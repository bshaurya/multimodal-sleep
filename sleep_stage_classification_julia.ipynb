{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "9f3df4c9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9f3df4c9",
        "outputId": "81afb85a-8af2-4ecb-8420-f5f76199fae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Julia Version 1.10.9\n",
            "Commit 5595d20a287 (2025-03-10 12:51 UTC)\n",
            "Build Info:\n",
            "  Official https://julialang.org/ release\n",
            "Platform Info:\n",
            "  OS: Linux (x86_64-linux-gnu)\n",
            "  CPU: 2 × Intel(R) Xeon(R) CPU @ 2.00GHz\n",
            "  WORD_SIZE: 64\n",
            "  LIBM: libopenlibm\n",
            "  LLVM: libLLVM-15.0.7 (ORCJIT, skylake-avx512)\n",
            "Threads: 2 default, 0 interactive, 1 GC (on 2 virtual cores)\n",
            "Environment:\n",
            "  LD_LIBRARY_PATH = /usr/lib64-nvidia\n",
            "  JULIA_NUM_THREADS = auto\n"
          ]
        }
      ],
      "source": [
        "using InteractiveUtils\n",
        "versioninfo()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9ec05f30",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ec05f30",
        "outputId": "1d1918df-6e08-489a-8375-9d11f91f5eb4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General.toml`\n",
            "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ScikitLearnBase ────────── v0.5.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ShowCases ──────────────── v0.1.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatisticalTraits ──────── v3.4.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NetworkLayout ──────────── v0.4.10\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Accessors ──────────────── v0.1.42\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LightGBM_jll ───────────── v3.3.5+1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ContextVariablesX ──────── v0.1.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CategoricalDistributions ─ v0.1.15\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m InitialValues ──────────── v0.3.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NearestNeighbors ───────── v0.4.21\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ZygoteRules ────────────── v0.2.7\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLUtils ────────────────── v0.4.8\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LearnAPI ───────────────── v1.0.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m EarlyStopping ──────────── v0.3.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PrettyPrint ────────────── v0.2.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NearestNeighborModels ──── v0.2.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJModels ──────────────── v0.17.9\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IterationControl ───────── v0.5.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m RealDot ────────────────── v0.1.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IRTools ────────────────── v0.4.15\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLCore ─────────────────── v1.0.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FiniteDiff ─────────────── v2.27.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JLD2 ───────────────────── v0.5.15\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Distances ──────────────── v0.10.12\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FLoopsBase ─────────────── v0.1.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LinearMaps ─────────────── v3.11.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ProgressLogging ────────── v0.1.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJFlow ────────────────── v0.5.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m libsvm_jll ─────────────── v3.25.0+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJLinearModels ────────── v0.10.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJFlux ────────────────── v0.6.6\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Zygote ─────────────────── v0.7.10\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OneHotArrays ───────────── v0.2.10\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DefineSingletons ───────── v0.1.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MicroCollections ───────── v0.2.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NameResolution ─────────── v0.1.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m NLSolversBase ──────────── v7.10.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ComputationalResources ─── v0.3.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ChainRules ─────────────── v1.72.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatisticalMeasures ────── v0.2.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LIBLINEAR ──────────────── v0.7.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BangBang ───────────────── v0.4.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PrettyPrinting ─────────── v0.4.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLStyle ────────────────── v0.4.17\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJIteration ───────────── v0.6.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Metalhead ──────────────── v0.9.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Glob ───────────────────── v1.3.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJ ────────────────────── v0.20.8\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PositiveFactorizations ─── v0.2.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FLoops ─────────────────── v0.2.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CategoricalArrays ──────── v0.10.8\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ARFFFiles ──────────────── v1.5.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJBase ────────────────── v1.8.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m FeatureSelection ───────── v0.2.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Flux ───────────────────── v0.16.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Combinatorics ──────────── v1.0.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LineSearches ───────────── v7.4.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m StatisticalMeasuresBase ── v0.1.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m CompositionsBase ───────── v0.1.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ScientificTypes ────────── v3.1.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m UnPack ─────────────────── v1.0.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DecisionTree ───────────── v0.12.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LightGBM ───────────────── v2.0.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m JuliaVariables ─────────── v0.2.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SparseInverseSubset ────── v0.1.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJDecisionTreeInterface ─ v0.4.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DifferentiationInterface ─ v0.7.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Transducers ────────────── v0.4.84\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJModelInterface ──────── v1.11.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m OpenML ─────────────────── v0.3.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m PartialFunctions ───────── v1.2.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJEnsembles ───────────── v0.4.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJTuning ──────────────── v0.8.8\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLFlowClient ───────────── v0.5.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m ScientificTypesBase ────── v3.0.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Optim ──────────────────── v1.13.2\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Baselet ────────────────── v0.1.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m SplittablesBase ────────── v0.1.15\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LatinHypercubeSampling ─── v1.9.0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m Parameters ─────────────── v0.12.3\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m liblinear_jll ──────────── v2.47.0+0\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m BSON ───────────────────── v0.3.9\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJLIBSVMInterface ─────── v0.2.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LIBSVM ─────────────────── v0.8.1\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m MLJBalancing ───────────── v0.1.5\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m IterativeSolvers ───────── v0.9.4\n",
            "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m EvoTrees ───────────────── v0.17.3\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.10/Project.toml`\n",
            "  \u001b[90m[324d7699] \u001b[39m\u001b[92m+ CategoricalArrays v0.10.8\u001b[39m\n",
            "  \u001b[90m[7806a523] \u001b[39m\u001b[92m+ DecisionTree v0.12.4\u001b[39m\n",
            "  \u001b[90m[f6006082] \u001b[39m\u001b[92m+ EvoTrees v0.17.3\u001b[39m\n",
            "  \u001b[90m[587475ba] \u001b[39m\u001b[92m+ Flux v0.16.4\u001b[39m\n",
            "  \u001b[90m[c27321d9] \u001b[39m\u001b[92m+ Glob v1.3.1\u001b[39m\n",
            "  \u001b[90m[b1bec4e5] \u001b[39m\u001b[92m+ LIBSVM v0.8.1\u001b[39m\n",
            "  \u001b[90m[7acf609c] \u001b[39m\u001b[92m+ LightGBM v2.0.0\u001b[39m\n",
            "  \u001b[90m[add582a8] \u001b[39m\u001b[92m+ MLJ v0.20.8\u001b[39m\n",
            "  \u001b[90m[a7f614a8] \u001b[39m\u001b[92m+ MLJBase v1.8.1\u001b[39m\n",
            "  \u001b[90m[c6f25543] \u001b[39m\u001b[92m+ MLJDecisionTreeInterface v0.4.2\u001b[39m\n",
            "  \u001b[90m[094fc8d1] \u001b[39m\u001b[92m+ MLJFlux v0.6.6\u001b[39m\n",
            "  \u001b[90m[61c7150f] \u001b[39m\u001b[92m+ MLJLIBSVMInterface v0.2.1\u001b[39m\n",
            "  \u001b[90m[6ee0df7b] \u001b[39m\u001b[92m+ MLJLinearModels v0.10.1\u001b[39m\n",
            "  \u001b[90m[e80e1ace] \u001b[39m\u001b[92m+ MLJModelInterface v1.11.1\u001b[39m\n",
            "  \u001b[90m[d491faf4] \u001b[39m\u001b[92m+ MLJModels v0.17.9\u001b[39m\n",
            "  \u001b[90m[636a865e] \u001b[39m\u001b[92m+ NearestNeighborModels v0.2.3\u001b[39m\n",
            "  \u001b[90m[2913bbd2] \u001b[39m\u001b[92m+ StatsBase v0.34.5\u001b[39m\n",
            "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `~/.julia/environments/v1.10/Manifest.toml`\n",
            "  \u001b[90m[da404889] \u001b[39m\u001b[92m+ ARFFFiles v1.5.0\u001b[39m\n",
            "  \u001b[90m[7d9f7c33] \u001b[39m\u001b[92m+ Accessors v0.1.42\u001b[39m\n",
            "  \u001b[90m[fbb218c0] \u001b[39m\u001b[92m+ BSON v0.3.9\u001b[39m\n",
            "  \u001b[90m[198e06fe] \u001b[39m\u001b[92m+ BangBang v0.4.4\u001b[39m\n",
            "  \u001b[90m[9718e550] \u001b[39m\u001b[92m+ Baselet v0.1.1\u001b[39m\n",
            "  \u001b[90m[324d7699] \u001b[39m\u001b[92m+ CategoricalArrays v0.10.8\u001b[39m\n",
            "  \u001b[90m[af321ab8] \u001b[39m\u001b[92m+ CategoricalDistributions v0.1.15\u001b[39m\n",
            "  \u001b[90m[082447d4] \u001b[39m\u001b[92m+ ChainRules v1.72.5\u001b[39m\n",
            "  \u001b[90m[861a8166] \u001b[39m\u001b[92m+ Combinatorics v1.0.3\u001b[39m\n",
            "  \u001b[90m[a33af91c] \u001b[39m\u001b[92m+ CompositionsBase v0.1.2\u001b[39m\n",
            "  \u001b[90m[ed09eef8] \u001b[39m\u001b[92m+ ComputationalResources v0.3.2\u001b[39m\n",
            "  \u001b[90m[6add18c4] \u001b[39m\u001b[92m+ ContextVariablesX v0.1.3\u001b[39m\n",
            "  \u001b[90m[7806a523] \u001b[39m\u001b[92m+ DecisionTree v0.12.4\u001b[39m\n",
            "  \u001b[90m[244e2a9f] \u001b[39m\u001b[92m+ DefineSingletons v0.1.2\u001b[39m\n",
            "  \u001b[90m[a0c0ee7d] \u001b[39m\u001b[92m+ DifferentiationInterface v0.7.2\u001b[39m\n",
            "  \u001b[90m[b4f34e82] \u001b[39m\u001b[92m+ Distances v0.10.12\u001b[39m\n",
            "  \u001b[90m[792122b4] \u001b[39m\u001b[92m+ EarlyStopping v0.3.0\u001b[39m\n",
            "  \u001b[90m[f6006082] \u001b[39m\u001b[92m+ EvoTrees v0.17.3\u001b[39m\n",
            "  \u001b[90m[cc61a311] \u001b[39m\u001b[92m+ FLoops v0.2.2\u001b[39m\n",
            "  \u001b[90m[b9860ae5] \u001b[39m\u001b[92m+ FLoopsBase v0.1.1\u001b[39m\n",
            "  \u001b[90m[33837fe5] \u001b[39m\u001b[92m+ FeatureSelection v0.2.2\u001b[39m\n",
            "  \u001b[90m[6a86dc24] \u001b[39m\u001b[92m+ FiniteDiff v2.27.0\u001b[39m\n",
            "  \u001b[90m[587475ba] \u001b[39m\u001b[92m+ Flux v0.16.4\u001b[39m\n",
            "  \u001b[90m[c27321d9] \u001b[39m\u001b[92m+ Glob v1.3.1\u001b[39m\n",
            "  \u001b[90m[7869d1d1] \u001b[39m\u001b[92m+ IRTools v0.4.15\u001b[39m\n",
            "  \u001b[90m[22cec73e] \u001b[39m\u001b[92m+ InitialValues v0.3.1\u001b[39m\n",
            "  \u001b[90m[b3c1a2ee] \u001b[39m\u001b[92m+ IterationControl v0.5.4\u001b[39m\n",
            "  \u001b[90m[42fd0dbc] \u001b[39m\u001b[92m+ IterativeSolvers v0.9.4\u001b[39m\n",
            "  \u001b[90m[033835bb] \u001b[39m\u001b[92m+ JLD2 v0.5.15\u001b[39m\n",
            "  \u001b[90m[b14d175d] \u001b[39m\u001b[92m+ JuliaVariables v0.2.4\u001b[39m\n",
            "  \u001b[90m[2d691ee1] \u001b[39m\u001b[92m+ LIBLINEAR v0.7.1\u001b[39m\n",
            "  \u001b[90m[b1bec4e5] \u001b[39m\u001b[92m+ LIBSVM v0.8.1\u001b[39m\n",
            "  \u001b[90m[a5e1c1ea] \u001b[39m\u001b[92m+ LatinHypercubeSampling v1.9.0\u001b[39m\n",
            "  \u001b[90m[92ad9a40] \u001b[39m\u001b[92m+ LearnAPI v1.0.1\u001b[39m\n",
            "  \u001b[90m[7acf609c] \u001b[39m\u001b[92m+ LightGBM v2.0.0\u001b[39m\n",
            "  \u001b[90m[d3d80556] \u001b[39m\u001b[92m+ LineSearches v7.4.0\u001b[39m\n",
            "  \u001b[90m[7a12625a] \u001b[39m\u001b[92m+ LinearMaps v3.11.4\u001b[39m\n",
            "  \u001b[90m[c2834f40] \u001b[39m\u001b[92m+ MLCore v1.0.0\u001b[39m\n",
            "\u001b[33m⌅\u001b[39m \u001b[90m[64a0f543] \u001b[39m\u001b[92m+ MLFlowClient v0.5.1\u001b[39m\n",
            "  \u001b[90m[add582a8] \u001b[39m\u001b[92m+ MLJ v0.20.8\u001b[39m\n",
            "  \u001b[90m[45f359ea] \u001b[39m\u001b[92m+ MLJBalancing v0.1.5\u001b[39m\n",
            "  \u001b[90m[a7f614a8] \u001b[39m\u001b[92m+ MLJBase v1.8.1\u001b[39m\n",
            "  \u001b[90m[c6f25543] \u001b[39m\u001b[92m+ MLJDecisionTreeInterface v0.4.2\u001b[39m\n",
            "  \u001b[90m[50ed68f4] \u001b[39m\u001b[92m+ MLJEnsembles v0.4.3\u001b[39m\n",
            "  \u001b[90m[7b7b8358] \u001b[39m\u001b[92m+ MLJFlow v0.5.0\u001b[39m\n",
            "  \u001b[90m[094fc8d1] \u001b[39m\u001b[92m+ MLJFlux v0.6.6\u001b[39m\n",
            "  \u001b[90m[614be32b] \u001b[39m\u001b[92m+ MLJIteration v0.6.3\u001b[39m\n",
            "  \u001b[90m[61c7150f] \u001b[39m\u001b[92m+ MLJLIBSVMInterface v0.2.1\u001b[39m\n",
            "  \u001b[90m[6ee0df7b] \u001b[39m\u001b[92m+ MLJLinearModels v0.10.1\u001b[39m\n",
            "  \u001b[90m[e80e1ace] \u001b[39m\u001b[92m+ MLJModelInterface v1.11.1\u001b[39m\n",
            "  \u001b[90m[d491faf4] \u001b[39m\u001b[92m+ MLJModels v0.17.9\u001b[39m\n",
            "  \u001b[90m[03970b2e] \u001b[39m\u001b[92m+ MLJTuning v0.8.8\u001b[39m\n",
            "  \u001b[90m[d8e11817] \u001b[39m\u001b[92m+ MLStyle v0.4.17\u001b[39m\n",
            "  \u001b[90m[f1d291b0] \u001b[39m\u001b[92m+ MLUtils v0.4.8\u001b[39m\n",
            "  \u001b[90m[dbeba491] \u001b[39m\u001b[92m+ Metalhead v0.9.5\u001b[39m\n",
            "  \u001b[90m[128add7d] \u001b[39m\u001b[92m+ MicroCollections v0.2.0\u001b[39m\n",
            "  \u001b[90m[d41bc354] \u001b[39m\u001b[92m+ NLSolversBase v7.10.0\u001b[39m\n",
            "  \u001b[90m[71a1bf82] \u001b[39m\u001b[92m+ NameResolution v0.1.5\u001b[39m\n",
            "  \u001b[90m[636a865e] \u001b[39m\u001b[92m+ NearestNeighborModels v0.2.3\u001b[39m\n",
            "  \u001b[90m[b8a86587] \u001b[39m\u001b[92m+ NearestNeighbors v0.4.21\u001b[39m\n",
            "  \u001b[90m[46757867] \u001b[39m\u001b[92m+ NetworkLayout v0.4.10\u001b[39m\n",
            "  \u001b[90m[0b1bfda6] \u001b[39m\u001b[92m+ OneHotArrays v0.2.10\u001b[39m\n",
            "  \u001b[90m[8b6db2d4] \u001b[39m\u001b[92m+ OpenML v0.3.2\u001b[39m\n",
            "  \u001b[90m[429524aa] \u001b[39m\u001b[92m+ Optim v1.13.2\u001b[39m\n",
            "  \u001b[90m[d96e819e] \u001b[39m\u001b[92m+ Parameters v0.12.3\u001b[39m\n",
            "  \u001b[90m[570af359] \u001b[39m\u001b[92m+ PartialFunctions v1.2.1\u001b[39m\n",
            "  \u001b[90m[85a6dd25] \u001b[39m\u001b[92m+ PositiveFactorizations v0.2.4\u001b[39m\n",
            "  \u001b[90m[8162dcfd] \u001b[39m\u001b[92m+ PrettyPrint v0.2.0\u001b[39m\n",
            "  \u001b[90m[54e16d92] \u001b[39m\u001b[92m+ PrettyPrinting v0.4.2\u001b[39m\n",
            "  \u001b[90m[33c8b6b6] \u001b[39m\u001b[92m+ ProgressLogging v0.1.5\u001b[39m\n",
            "  \u001b[90m[c1ae055f] \u001b[39m\u001b[92m+ RealDot v0.1.0\u001b[39m\n",
            "  \u001b[90m[321657f4] \u001b[39m\u001b[92m+ ScientificTypes v3.1.0\u001b[39m\n",
            "  \u001b[90m[30f210dd] \u001b[39m\u001b[92m+ ScientificTypesBase v3.0.0\u001b[39m\n",
            "  \u001b[90m[6e75b9c4] \u001b[39m\u001b[92m+ ScikitLearnBase v0.5.0\u001b[39m\n",
            "  \u001b[90m[605ecd9f] \u001b[39m\u001b[92m+ ShowCases v0.1.0\u001b[39m\n",
            "  \u001b[90m[dc90abb0] \u001b[39m\u001b[92m+ SparseInverseSubset v0.1.2\u001b[39m\n",
            "  \u001b[90m[171d559e] \u001b[39m\u001b[92m+ SplittablesBase v0.1.15\u001b[39m\n",
            "  \u001b[90m[a19d573c] \u001b[39m\u001b[92m+ StatisticalMeasures v0.2.1\u001b[39m\n",
            "  \u001b[90m[c062fc1d] \u001b[39m\u001b[92m+ StatisticalMeasuresBase v0.1.2\u001b[39m\n",
            "  \u001b[90m[64bff920] \u001b[39m\u001b[92m+ StatisticalTraits v3.4.0\u001b[39m\n",
            "  \u001b[90m[28d57a85] \u001b[39m\u001b[92m+ Transducers v0.4.84\u001b[39m\n",
            "  \u001b[90m[3a884ed6] \u001b[39m\u001b[92m+ UnPack v1.0.2\u001b[39m\n",
            "  \u001b[90m[e88e6eb3] \u001b[39m\u001b[92m+ Zygote v0.7.10\u001b[39m\n",
            "  \u001b[90m[700de1a5] \u001b[39m\u001b[92m+ ZygoteRules v0.2.7\u001b[39m\n",
            "\u001b[33m⌅\u001b[39m \u001b[90m[0e4427ef] \u001b[39m\u001b[92m+ LightGBM_jll v3.3.5+1\u001b[39m\n",
            "  \u001b[90m[275f1f90] \u001b[39m\u001b[92m+ liblinear_jll v2.47.0+0\u001b[39m\n",
            "  \u001b[90m[08558c22] \u001b[39m\u001b[92m+ libsvm_jll v3.25.0+0\u001b[39m\n",
            "\u001b[36m\u001b[1m        Info\u001b[22m\u001b[39m Packages marked with \u001b[33m⌅\u001b[39m have new versions available but compatibility constraints restrict them from upgrading. To see why use `status --outdated -m`\n",
            "\u001b[32m\u001b[1m    Building\u001b[22m\u001b[39m LightGBM → `~/.julia/scratchspaces/44cfe95a-1eb2-52ea-b672-e2afdf69b78f/fa2e05581f7393693de1c3a3ca79ae2ded9394ac/build.log`\n",
            "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m packages...\n",
            "   2311.6 ms\u001b[32m  ✓ \u001b[39mGlob\n",
            "   2494.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mInitialValues\u001b[39m\n",
            "   1818.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mRealDot\u001b[39m\n",
            "   1471.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mContextVariablesX\u001b[39m\n",
            "   1726.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mProgressLogging\u001b[39m\n",
            "   2208.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLearnAPI\u001b[39m\n",
            "    642.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mUnPack\u001b[39m\n",
            "   1029.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPrettyPrint\u001b[39m\n",
            "   2758.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface\u001b[39m\n",
            "    847.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDefineSingletons\u001b[39m\n",
            "   1716.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBSON\u001b[39m\n",
            "   1734.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCombinatorics\u001b[39m\n",
            "    956.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mScientificTypesBase\u001b[39m\n",
            "   1002.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPositiveFactorizations\u001b[39m\n",
            "   9272.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPrettyPrinting\u001b[39m\n",
            "   3629.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLinearMaps\u001b[39m\n",
            "   1098.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mShowCases\u001b[39m\n",
            "    973.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCompositionsBase\u001b[39m\n",
            "   1997.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mComputationalResources\u001b[39m\n",
            "   3495.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBaselet\u001b[39m\n",
            "   2343.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mZygoteRules\u001b[39m\n",
            "   1478.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mPartialFunctions\u001b[39m\n",
            "   1667.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSparseInverseSubset\u001b[39m\n",
            "   3764.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mIRTools\u001b[39m\n",
            "   2833.1 ms\u001b[32m  ✓ \u001b[39mCategoricalArrays\n",
            "   1976.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLCore\u001b[39m\n",
            "   2040.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mSplittablesBase\u001b[39m\n",
            "   1627.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mliblinear_jll\u001b[39m\n",
            "   1707.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mlibsvm_jll\u001b[39m\n",
            "   1288.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLightGBM_jll\u001b[39m\n",
            "   1884.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDistances\u001b[39m\n",
            "   1836.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mScikitLearnBase\u001b[39m\n",
            "   1591.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mEarlyStopping\u001b[39m\n",
            "   4674.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mIterativeSolvers\u001b[39m\n",
            "   2618.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLatinHypercubeSampling\u001b[39m\n",
            "   1663.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFiniteDiff\u001b[39m\n",
            "   3137.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNetworkLayout\u001b[39m\n",
            "   2732.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOneHotArrays\u001b[39m\n",
            "  14137.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLDataDevices → MLDataDevicesCUDAExt\u001b[39m\n",
            "   1479.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFLoopsBase\u001b[39m\n",
            "  58290.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLStyle\u001b[39m\n",
            "    965.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mParameters\u001b[39m\n",
            "   1029.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNameResolution\u001b[39m\n",
            "   1081.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface → DifferentiationInterfaceGPUArraysCoreExt\u001b[39m\n",
            "   1340.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface → DifferentiationInterfaceForwardDiffExt\u001b[39m\n",
            "   1189.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface → DifferentiationInterfaceChainRulesCoreExt\u001b[39m\n",
            "   1482.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface → DifferentiationInterfaceStaticArraysExt\u001b[39m\n",
            "    946.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStatisticalTraits\u001b[39m\n",
            "   1422.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface → DifferentiationInterfaceSparseArraysExt\u001b[39m\n",
            "    935.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLinearMaps → LinearMapsChainRulesCoreExt\u001b[39m\n",
            "   1967.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLinearMaps → LinearMapsSparseArraysExt\u001b[39m\n",
            "    701.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCompositionsBase → CompositionsBaseInverseFunctionsExt\u001b[39m\n",
            "   2207.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLFlowClient\u001b[39m\n",
            "   1434.1 ms\u001b[32m  ✓ \u001b[39mCategoricalArrays → CategoricalArraysJSONExt\n",
            "   3415.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mARFFFiles\u001b[39m\n",
            "   1803.9 ms\u001b[32m  ✓ \u001b[39mCategoricalArrays → CategoricalArraysRecipesBaseExt\n",
            "   1555.9 ms\u001b[32m  ✓ \u001b[39mCategoricalArrays → CategoricalArraysSentinelArraysExt\n",
            "   1640.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLIBLINEAR\u001b[39m\n",
            "   1332.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDistances → DistancesSparseArraysExt\u001b[39m\n",
            "  13155.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mChainRules\u001b[39m\n",
            "   2821.2 ms\u001b[32m  ✓ \u001b[39mDecisionTree\n",
            "   1724.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFiniteDiff → FiniteDiffSparseArraysExt\u001b[39m\n",
            "   3875.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mIterationControl\u001b[39m\n",
            "   2033.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFiniteDiff → FiniteDiffStaticArraysExt\u001b[39m\n",
            "   1261.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface → DifferentiationInterfaceFiniteDiffExt\u001b[39m\n",
            "   2712.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLDataDevices → MLDataDevicesOneHotArraysExt\u001b[39m\n",
            "  13086.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLuxLib → LuxLibCUDAExt\u001b[39m\n",
            "   5402.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mJuliaVariables\u001b[39m\n",
            "   2791.2 ms\u001b[32m  ✓ \u001b[39mMLJModelInterface\n",
            "   3991.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mScientificTypes\u001b[39m\n",
            "   3985.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface → DifferentiationInterfaceEnzymeExt\u001b[39m\n",
            " 100912.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mJLD2\u001b[39m\n",
            "   1267.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLinearMaps → LinearMapsStatisticsExt\u001b[39m\n",
            "   4475.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOpenML\u001b[39m\n",
            "   6373.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors\u001b[39m\n",
            "   2513.0 ms\u001b[32m  ✓ \u001b[39mLIBSVM\n",
            "   1070.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDistances → DistancesChainRulesCoreExt\u001b[39m\n",
            "  44152.6 ms\u001b[32m  ✓ \u001b[39mReactant → ReactantOneHotArraysExt\n",
            "   5664.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNearestNeighbors\u001b[39m\n",
            "   1584.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLDataDevices → MLDataDevicesChainRulesExt\u001b[39m\n",
            "   1877.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mArrayInterface → ArrayInterfaceChainRulesExt\u001b[39m\n",
            "   2810.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mNLSolversBase\u001b[39m\n",
            "   2233.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFeatureSelection\u001b[39m\n",
            "   5234.6 ms\u001b[32m  ✓ \u001b[39mLightGBM\n",
            "   7756.4 ms\u001b[32m  ✓ \u001b[39mEvoTrees\n",
            "   2575.8 ms\u001b[32m  ✓ \u001b[39mMLJDecisionTreeInterface\n",
            "   1531.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mJLD2 → UnPackExt\u001b[39m\n",
            "   1151.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → LinearAlgebraExt\u001b[39m\n",
            "   3982.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mCategoricalDistributions\u001b[39m\n",
            "   3496.1 ms\u001b[32m  ✓ \u001b[39mMLJLIBSVMInterface\n",
            "   4159.0 ms\u001b[32m  ✓ \u001b[39mNearestNeighborModels\n",
            "   3716.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mLineSearches\u001b[39m\n",
            "   1261.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → TestExt\u001b[39m\n",
            "   1659.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → StaticArraysExt\u001b[39m\n",
            "   1246.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → StructArraysExt\u001b[39m\n",
            "   1281.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → IntervalSetsExt\u001b[39m\n",
            "   2739.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang\u001b[39m\n",
            "   1642.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mAccessors → UnitfulExt\u001b[39m\n",
            "  15278.2 ms\u001b[32m  ✓ \u001b[39mEvoTrees → EvoTreesCUDAExt\n",
            "   7275.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mOptim\u001b[39m\n",
            "   1660.3 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangStaticArraysExt\u001b[39m\n",
            "   1184.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangChainRulesCoreExt\u001b[39m\n",
            "  14861.9 ms\u001b[32m  ✓ \u001b[39mMLJModels\n",
            "   1246.0 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangTablesExt\u001b[39m\n",
            "   1667.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMicroCollections\u001b[39m\n",
            "   1139.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangStructArraysExt\u001b[39m\n",
            "   4125.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mBangBang → BangBangDataFramesExt\u001b[39m\n",
            "   7540.8 ms\u001b[32m  ✓ \u001b[39mMLJLinearModels\n",
            "   4184.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mTransducers\u001b[39m\n",
            "   1451.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mTransducers → TransducersAdaptExt\u001b[39m\n",
            "   3654.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mTransducers → TransducersDataFramesExt\u001b[39m\n",
            "   5971.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mFLoops\u001b[39m\n",
            "   9978.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLUtils\u001b[39m\n",
            "   4981.9 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLDataDevices → MLDataDevicesMLUtilsExt\u001b[39m\n",
            "   4721.7 ms\u001b[32m  ✓ \u001b[39mLux → LuxMLUtilsExt\n",
            "  93500.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mZygote\u001b[39m\n",
            "  15435.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStatisticalMeasuresBase\u001b[39m\n",
            "   3960.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLDataDevices → MLDataDevicesZygoteExt\u001b[39m\n",
            "   4496.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mZygote → ZygoteColorsExt\u001b[39m\n",
            "   6347.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mZygote → ZygoteDistancesExt\u001b[39m\n",
            "   3050.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mDifferentiationInterface → DifferentiationInterfaceZygoteExt\u001b[39m\n",
            "   5936.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLJEnsembles\u001b[39m\n",
            "  12528.8 ms\u001b[32m  ✓ \u001b[39mMLJBase\n",
            "   6861.8 ms\u001b[32m  ✓ \u001b[39mLux → LuxZygoteExt\n",
            "   8768.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLJBalancing\u001b[39m\n",
            "  16316.5 ms\u001b[32m  ✓ \u001b[39mFlux\n",
            "   6806.5 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLJTuning\u001b[39m\n",
            "   7930.4 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLJFlow\u001b[39m\n",
            "    898.4 ms\u001b[32m  ✓ \u001b[39mFlux → FluxCUDAExt\n",
            "  10267.6 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMLJIteration\u001b[39m\n",
            "   7252.6 ms\u001b[32m  ✓ \u001b[39mLux → LuxFluxExt\n",
            "  53764.2 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStatisticalMeasures\u001b[39m\n",
            "   7075.7 ms\u001b[32m  ✓ \u001b[39m\u001b[90mStatisticalMeasures → ScientificTypesExt\u001b[39m\n",
            "  17334.8 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMetalhead\u001b[39m\n",
            "   6346.9 ms\u001b[32m  ✓ \u001b[39mMLJBase → DefaultMeasuresExt\n",
            "  10728.1 ms\u001b[32m  ✓ \u001b[39mMLJFlux\n",
            "  42851.1 ms\u001b[32m  ✓ \u001b[39mFlux → FluxEnzymeExt\n",
            "  16492.1 ms\u001b[32m  ✓ \u001b[39m\u001b[90mMetalhead → MetalheadCUDAExt\u001b[39m\n",
            "   6619.6 ms\u001b[32m  ✓ \u001b[39mMLJ\n",
            "  139 dependencies successfully precompiled in 324 seconds. 459 already precompiled.\n",
            "  \u001b[33m1\u001b[39m dependency had output during precompilation:\u001b[33m\n",
            "┌ \u001b[39mMetalhead → MetalheadCUDAExt\u001b[33m\n",
            "│  \u001b[39m\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mPackage cuDNN not found in current path.\u001b[33m\n",
            "│  \u001b[39m\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- Run `import Pkg; Pkg.add(\"cuDNN\")` to install the cuDNN package, then restart julia.\u001b[33m\n",
            "│  \u001b[39m\u001b[33m\u001b[1m│ \u001b[22m\u001b[39m- If cuDNN is not installed, some Flux functionalities will not be available when running on the GPU.\u001b[33m\n",
            "│  \u001b[39m\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ FluxCUDAExt ~/.julia/packages/Flux/9PibT/ext/FluxCUDAExt/FluxCUDAExt.jl:10\u001b[39m\u001b[33m\n",
            "└  \u001b[39m\n"
          ]
        }
      ],
      "source": [
        "using Pkg\n",
        "Pkg.add([\n",
        "    \"CSV\", \"DataFrames\", \"MLJ\", \"MLJFlux\", \"Flux\", \"Plots\", \"StatsBase\",\n",
        "    \"CategoricalArrays\", \"MLJBase\", \"Glob\", \"DecisionTree\", \"MLJDecisionTreeInterface\",\n",
        "    \"NearestNeighborModels\", \"MLJLinearModels\", \"LIBSVM\", \"EvoTrees\", \"LightGBM\",\n",
        "    \"MLJLIBSVMInterface\",\"MLJModels\",\n",
        "    \"MLJModelInterface\"\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "d219bf8f",
      "metadata": {
        "id": "d219bf8f"
      },
      "outputs": [],
      "source": [
        "using CSV, DataFrames, MLJ, Flux, Plots, StatsBase, CategoricalArrays, MLJFlux"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "ac1b877a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "ac1b877a",
        "outputId": "7091d368-c56e-4fa4-f2e6-559ba6644652"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div style = \"float: left;\"><span>5×34 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">sid</th><th style = \"text-align: left;\">rMSSD</th><th style = \"text-align: left;\">SDNN</th><th style = \"text-align: left;\">pNN50</th><th style = \"text-align: left;\">LF_frequency_peak</th><th style = \"text-align: left;\">LF_frequency_power</th><th style = \"text-align: left;\">HF_frequency_peak</th><th style = \"text-align: left;\">HF_frequency_power</th><th style = \"text-align: left;\">total_power</th><th style = \"text-align: left;\">IBI_mean</th><th style = \"text-align: left;\">IBI_median</th><th style = \"text-align: left;\">IBI_max</th><th style = \"text-align: left;\">IBI_min</th><th style = \"text-align: left;\">IBI_std</th><th style = \"text-align: left;\">HR_mean</th><th style = \"text-align: left;\">HR_median</th><th style = \"text-align: left;\">HR_max</th><th style = \"text-align: left;\">HR_min</th><th style = \"text-align: left;\">HR_std</th><th style = \"text-align: left;\">HRV_ApEn</th><th style = \"text-align: left;\">HRV_SampEn</th><th style = \"text-align: left;\">HRV_ShanEn</th><th style = \"text-align: left;\">HRV_FuzzyEn</th><th style = \"text-align: left;\">HRV_MSEn</th><th style = \"text-align: left;\">HRV_CMSEn</th><th style = \"text-align: left;\">HRV_RCMSEn</th><th style = \"text-align: left;\">HRV_CD</th><th style = \"text-align: left;\">HRV_HFD</th><th style = \"text-align: left;\">HRV_KFD</th><th style = \"text-align: left;\">HRV_LZC</th><th style = \"text-align: left;\">circadian_cosine_start</th><th style = \"text-align: left;\">circadian_cosine_decay</th><th style = \"text-align: left;\">circadian_cosine_linear</th><th style = \"text-align: left;\">Sleep_Stage</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String7\" style = \"text-align: left;\">String7</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"String1\" style = \"text-align: left;\">String1</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">S002</td><td style = \"text-align: right;\">291.254</td><td style = \"text-align: right;\">198.942</td><td style = \"text-align: right;\">64.6259</td><td style = \"text-align: right;\">0.0916667</td><td style = \"text-align: right;\">204.331</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">483.371</td><td style = \"text-align: right;\">5739.3</td><td style = \"text-align: right;\">0.854366</td><td style = \"text-align: right;\">0.84375</td><td style = \"text-align: right;\">1.15625</td><td style = \"text-align: right;\">0.671875</td><td style = \"text-align: right;\">0.131768</td><td style = \"text-align: right;\">0.214561</td><td style = \"text-align: right;\">0.191428</td><td style = \"text-align: right;\">0.390688</td><td style = \"text-align: right;\">0.06712</td><td style = \"text-align: right;\">0.105759</td><td style = \"text-align: right;\">0.792569</td><td style = \"text-align: right;\">1.20705</td><td style = \"text-align: right;\">4.81094</td><td style = \"text-align: right;\">1.04305</td><td style = \"text-align: right;\">0.799375</td><td style = \"text-align: right;\">1.3601</td><td style = \"text-align: right;\">1.39029</td><td style = \"text-align: right;\">1.32066</td><td style = \"text-align: right;\">2.00169</td><td style = \"text-align: right;\">3.33634</td><td style = \"text-align: right;\">1.17546</td><td style = \"text-align: right;\">0.0119814</td><td style = \"text-align: right;\">0.98259</td><td style = \"text-align: right;\">0.00381388</td><td style = \"text-align: left;\">P</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">S002</td><td style = \"text-align: right;\">386.275</td><td style = \"text-align: right;\">286.862</td><td style = \"text-align: right;\">82.9932</td><td style = \"text-align: right;\">0.0833333</td><td style = \"text-align: right;\">121.643</td><td style = \"text-align: right;\">0.158333</td><td style = \"text-align: right;\">401.012</td><td style = \"text-align: right;\">4206.22</td><td style = \"text-align: right;\">0.739913</td><td style = \"text-align: right;\">0.734375</td><td style = \"text-align: right;\">0.859375</td><td style = \"text-align: right;\">0.734375</td><td style = \"text-align: right;\">0.0146324</td><td style = \"text-align: right;\">0.54212</td><td style = \"text-align: right;\">0.210623</td><td style = \"text-align: right;\">1.72609</td><td style = \"text-align: right;\">0.12379</td><td style = \"text-align: right;\">0.518313</td><td style = \"text-align: right;\">0.731853</td><td style = \"text-align: right;\">1.82735</td><td style = \"text-align: right;\">5.66427</td><td style = \"text-align: right;\">1.46808</td><td style = \"text-align: right;\">1.26058</td><td style = \"text-align: right;\">1.17599</td><td style = \"text-align: right;\">1.53516</td><td style = \"text-align: right;\">1.92788</td><td style = \"text-align: right;\">1.99834</td><td style = \"text-align: right;\">4.17921</td><td style = \"text-align: right;\">1.0775</td><td style = \"text-align: right;\">0.023961</td><td style = \"text-align: right;\">0.965483</td><td style = \"text-align: right;\">0.00762777</td><td style = \"text-align: left;\">P</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">S002</td><td style = \"text-align: right;\">310.197</td><td style = \"text-align: right;\">218.362</td><td style = \"text-align: right;\">67.3203</td><td style = \"text-align: right;\">0.0833333</td><td style = \"text-align: right;\">163.949</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">469.285</td><td style = \"text-align: right;\">4542.46</td><td style = \"text-align: right;\">0.765466</td><td style = \"text-align: right;\">0.734375</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">0.734375</td><td style = \"text-align: right;\">0.0743457</td><td style = \"text-align: right;\">0.911839</td><td style = \"text-align: right;\">0.785093</td><td style = \"text-align: right;\">1.78276</td><td style = \"text-align: right;\">0.288316</td><td style = \"text-align: right;\">0.550858</td><td style = \"text-align: right;\">0.666223</td><td style = \"text-align: right;\">0.996238</td><td style = \"text-align: right;\">5.03294</td><td style = \"text-align: right;\">1.08203</td><td style = \"text-align: right;\">1.29357</td><td style = \"text-align: right;\">1.16307</td><td style = \"text-align: right;\">1.22496</td><td style = \"text-align: right;\">1.38469</td><td style = \"text-align: right;\">1.98497</td><td style = \"text-align: right;\">3.4982</td><td style = \"text-align: right;\">1.09098</td><td style = \"text-align: right;\">0.0359373</td><td style = \"text-align: right;\">0.948673</td><td style = \"text-align: right;\">0.0114416</td><td style = \"text-align: left;\">P</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">S002</td><td style = \"text-align: right;\">318.613</td><td style = \"text-align: right;\">249.197</td><td style = \"text-align: right;\">69.9301</td><td style = \"text-align: right;\">0.0916667</td><td style = \"text-align: right;\">280.756</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">193.683</td><td style = \"text-align: right;\">4581.74</td><td style = \"text-align: right;\">0.768691</td><td style = \"text-align: right;\">0.78125</td><td style = \"text-align: right;\">0.90625</td><td style = \"text-align: right;\">0.59375</td><td style = \"text-align: right;\">0.0754652</td><td style = \"text-align: right;\">0.437562</td><td style = \"text-align: right;\">0.425421</td><td style = \"text-align: right;\">0.546987</td><td style = \"text-align: right;\">0.354126</td><td style = \"text-align: right;\">0.040068</td><td style = \"text-align: right;\">0.749222</td><td style = \"text-align: right;\">0.966588</td><td style = \"text-align: right;\">5.10161</td><td style = \"text-align: right;\">1.23342</td><td style = \"text-align: right;\">1.14552</td><td style = \"text-align: right;\">1.2085</td><td style = \"text-align: right;\">1.40636</td><td style = \"text-align: right;\">1.40856</td><td style = \"text-align: right;\">1.96053</td><td style = \"text-align: right;\">3.46928</td><td style = \"text-align: right;\">1.10152</td><td style = \"text-align: right;\">0.0479083</td><td style = \"text-align: right;\">0.932157</td><td style = \"text-align: right;\">0.0152555</td><td style = \"text-align: left;\">P</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">S002</td><td style = \"text-align: right;\">304.647</td><td style = \"text-align: right;\">206.281</td><td style = \"text-align: right;\">71.8121</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">338.04</td><td style = \"text-align: right;\">0.191667</td><td style = \"text-align: right;\">620.805</td><td style = \"text-align: right;\">5660.8</td><td style = \"text-align: right;\">0.854274</td><td style = \"text-align: right;\">0.90625</td><td style = \"text-align: right;\">1.01562</td><td style = \"text-align: right;\">0.640625</td><td style = \"text-align: right;\">0.0854323</td><td style = \"text-align: right;\">0.0896814</td><td style = \"text-align: right;\">0.115564</td><td style = \"text-align: right;\">0.423593</td><td style = \"text-align: right;\">-0.246393</td><td style = \"text-align: right;\">0.243694</td><td style = \"text-align: right;\">0.710629</td><td style = \"text-align: right;\">1.29152</td><td style = \"text-align: right;\">5.22051</td><td style = \"text-align: right;\">1.25967</td><td style = \"text-align: right;\">1.20749</td><td style = \"text-align: right;\">1.39171</td><td style = \"text-align: right;\">1.58391</td><td style = \"text-align: right;\">1.51793</td><td style = \"text-align: right;\">1.99466</td><td style = \"text-align: right;\">4.39993</td><td style = \"text-align: right;\">1.16282</td><td style = \"text-align: right;\">0.0598725</td><td style = \"text-align: right;\">0.915928</td><td style = \"text-align: right;\">0.0190694</td><td style = \"text-align: left;\">P</td></tr></tbody></table></div>"
            ],
            "text/latex": [
              "\\begin{tabular}{r|cccccccc}\n",
              "\t& sid & rMSSD & SDNN & pNN50 & LF\\_frequency\\_peak & LF\\_frequency\\_power & HF\\_frequency\\_peak & \\\\\n",
              "\t\\hline\n",
              "\t& String7 & Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
              "\t\\hline\n",
              "\t1 & S002 & 291.254 & 198.942 & 64.6259 & 0.0916667 & 204.331 & 0.241667 & $\\dots$ \\\\\n",
              "\t2 & S002 & 386.275 & 286.862 & 82.9932 & 0.0833333 & 121.643 & 0.158333 & $\\dots$ \\\\\n",
              "\t3 & S002 & 310.197 & 218.362 & 67.3203 & 0.0833333 & 163.949 & 0.241667 & $\\dots$ \\\\\n",
              "\t4 & S002 & 318.613 & 249.197 & 69.9301 & 0.0916667 & 280.756 & 0.241667 & $\\dots$ \\\\\n",
              "\t5 & S002 & 304.647 & 206.281 & 71.8121 & 0.1 & 338.04 & 0.191667 & $\\dots$ \\\\\n",
              "\\end{tabular}\n"
            ],
            "text/plain": [
              "\u001b[1m5×34 DataFrame\n",
              "\u001b[1m Row │\u001b[1m sid     \u001b[1m rMSSD   \u001b[1m SDNN    \u001b[1m pNN50   \u001b[1m LF_frequency_peak \u001b[1m LF_frequency_pow ⋯\n",
              "     │\u001b[90m String7 \u001b[90m Float64 \u001b[90m Float64 \u001b[90m Float64 \u001b[90m Float64           \u001b[90m Float64          ⋯\n",
              "─────┼──────────────────────────────────────────────────────────────────────────\n",
              "   1 │ S002     291.254  198.942  64.6259          0.0916667             204.3 ⋯\n",
              "   2 │ S002     386.275  286.862  82.9932          0.0833333             121.6\n",
              "   3 │ S002     310.197  218.362  67.3203          0.0833333             163.9\n",
              "   4 │ S002     318.613  249.197  69.9301          0.0916667             280.7\n",
              "   5 │ S002     304.647  206.281  71.8121          0.1                   338.0 ⋯\n",
              "\u001b[36m                                                              29 columns omitted"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import Glob\n",
        "path = \"./cleaneddata\"\n",
        "files = Glob.glob(\"S*_cleaned_domain_features.csv\", path)\n",
        "\n",
        "df_all = DataFrame[]\n",
        "for file in files\n",
        "    push!(df_all, CSV.read(file, DataFrame))\n",
        "end\n",
        "\n",
        "data = reduce(vcat, df_all)\n",
        "first(data, 5)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "a6b4b4d6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 655
        },
        "id": "a6b4b4d6",
        "outputId": "c856a3cb-0852-450e-c64c-6b1aa699b8c5"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div><div style = \"float: left;\"><span>54652×31 DataFrame</span></div><div style = \"float: right;\"><span style = \"font-style: italic;\">54627 rows omitted</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">rMSSD</th><th style = \"text-align: left;\">SDNN</th><th style = \"text-align: left;\">pNN50</th><th style = \"text-align: left;\">LF_frequency_peak</th><th style = \"text-align: left;\">LF_frequency_power</th><th style = \"text-align: left;\">HF_frequency_peak</th><th style = \"text-align: left;\">HF_frequency_power</th><th style = \"text-align: left;\">total_power</th><th style = \"text-align: left;\">IBI_mean</th><th style = \"text-align: left;\">IBI_median</th><th style = \"text-align: left;\">IBI_max</th><th style = \"text-align: left;\">IBI_min</th><th style = \"text-align: left;\">IBI_std</th><th style = \"text-align: left;\">HR_mean</th><th style = \"text-align: left;\">HR_median</th><th style = \"text-align: left;\">HR_max</th><th style = \"text-align: left;\">HR_min</th><th style = \"text-align: left;\">HR_std</th><th style = \"text-align: left;\">HRV_ApEn</th><th style = \"text-align: left;\">HRV_ShanEn</th><th style = \"text-align: left;\">HRV_FuzzyEn</th><th style = \"text-align: left;\">HRV_MSEn</th><th style = \"text-align: left;\">HRV_CMSEn</th><th style = \"text-align: left;\">HRV_RCMSEn</th><th style = \"text-align: left;\">HRV_CD</th><th style = \"text-align: left;\">HRV_HFD</th><th style = \"text-align: left;\">HRV_KFD</th><th style = \"text-align: left;\">HRV_LZC</th><th style = \"text-align: left;\">circadian_cosine_start</th><th style = \"text-align: left;\">circadian_cosine_decay</th><th style = \"text-align: left;\">circadian_cosine_linear</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: right;\">485.018</td><td style = \"text-align: right;\">433.173</td><td style = \"text-align: right;\">87.9032</td><td style = \"text-align: right;\">0.0916667</td><td style = \"text-align: right;\">396.591</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">673.864</td><td style = \"text-align: right;\">6058.27</td><td style = \"text-align: right;\">0.885388</td><td style = \"text-align: right;\">0.953125</td><td style = \"text-align: right;\">0.953125</td><td style = \"text-align: right;\">0.8125</td><td style = \"text-align: right;\">0.0701784</td><td style = \"text-align: right;\">1.02479</td><td style = \"text-align: right;\">1.06524</td><td style = \"text-align: right;\">1.42354</td><td style = \"text-align: right;\">0.408968</td><td style = \"text-align: right;\">0.226097</td><td style = \"text-align: right;\">0.931941</td><td style = \"text-align: right;\">5.70279</td><td style = \"text-align: right;\">1.35855</td><td style = \"text-align: right;\">1.18724</td><td style = \"text-align: right;\">1.4379</td><td style = \"text-align: right;\">1.82889</td><td style = \"text-align: right;\">1.6382</td><td style = \"text-align: right;\">1.9931</td><td style = \"text-align: right;\">1.9935</td><td style = \"text-align: right;\">1.12164</td><td style = \"text-align: right;\">0.793536</td><td style = \"text-align: right;\">0.260901</td><td style = \"text-align: right;\">0.291762</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: right;\">422.248</td><td style = \"text-align: right;\">314.127</td><td style = \"text-align: right;\">85.6061</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">130.599</td><td style = \"text-align: right;\">0.233333</td><td style = \"text-align: right;\">639.783</td><td style = \"text-align: right;\">5492.36</td><td style = \"text-align: right;\">0.842592</td><td style = \"text-align: right;\">0.8125</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0720376</td><td style = \"text-align: right;\">1.19044</td><td style = \"text-align: right;\">1.12466</td><td style = \"text-align: right;\">1.57436</td><td style = \"text-align: right;\">0.952818</td><td style = \"text-align: right;\">0.171888</td><td style = \"text-align: right;\">0.778819</td><td style = \"text-align: right;\">5.74297</td><td style = \"text-align: right;\">1.65644</td><td style = \"text-align: right;\">1.38917</td><td style = \"text-align: right;\">1.38225</td><td style = \"text-align: right;\">1.79073</td><td style = \"text-align: right;\">1.87722</td><td style = \"text-align: right;\">1.99126</td><td style = \"text-align: right;\">3.48336</td><td style = \"text-align: right;\">1.17407</td><td style = \"text-align: right;\">0.795355</td><td style = \"text-align: right;\">0.259758</td><td style = \"text-align: right;\">0.292715</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: right;\">395.127</td><td style = \"text-align: right;\">297.914</td><td style = \"text-align: right;\">86.3636</td><td style = \"text-align: right;\">0.0916667</td><td style = \"text-align: right;\">177.055</td><td style = \"text-align: right;\">0.225</td><td style = \"text-align: right;\">517.887</td><td style = \"text-align: right;\">4873.61</td><td style = \"text-align: right;\">0.795717</td><td style = \"text-align: right;\">0.8125</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0376666</td><td style = \"text-align: right;\">1.01138</td><td style = \"text-align: right;\">1.06799</td><td style = \"text-align: right;\">1.57436</td><td style = \"text-align: right;\">-0.115687</td><td style = \"text-align: right;\">0.386523</td><td style = \"text-align: right;\">0.580465</td><td style = \"text-align: right;\">5.70448</td><td style = \"text-align: right;\">1.70338</td><td style = \"text-align: right;\">1.42043</td><td style = \"text-align: right;\">1.55365</td><td style = \"text-align: right;\">1.95231</td><td style = \"text-align: right;\">1.77674</td><td style = \"text-align: right;\">2.02138</td><td style = \"text-align: right;\">6.22896</td><td style = \"text-align: right;\">1.1207</td><td style = \"text-align: right;\">0.797167</td><td style = \"text-align: right;\">0.25862</td><td style = \"text-align: right;\">0.293669</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: right;\">406.78</td><td style = \"text-align: right;\">320.998</td><td style = \"text-align: right;\">86.0465</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">174.384</td><td style = \"text-align: right;\">0.15</td><td style = \"text-align: right;\">288.63</td><td style = \"text-align: right;\">4695.33</td><td style = \"text-align: right;\">0.781325</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0300324</td><td style = \"text-align: right;\">0.694124</td><td style = \"text-align: right;\">1.0072</td><td style = \"text-align: right;\">1.57436</td><td style = \"text-align: right;\">-0.351507</td><td style = \"text-align: right;\">0.666761</td><td style = \"text-align: right;\">0.745459</td><td style = \"text-align: right;\">5.77364</td><td style = \"text-align: right;\">1.62205</td><td style = \"text-align: right;\">1.60142</td><td style = \"text-align: right;\">1.32257</td><td style = \"text-align: right;\">1.72526</td><td style = \"text-align: right;\">1.82947</td><td style = \"text-align: right;\">2.0025</td><td style = \"text-align: right;\">4.41651</td><td style = \"text-align: right;\">1.08701</td><td style = \"text-align: right;\">0.798972</td><td style = \"text-align: right;\">0.257487</td><td style = \"text-align: right;\">0.294622</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: right;\">512.473</td><td style = \"text-align: right;\">380.493</td><td style = \"text-align: right;\">88.8889</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">275.937</td><td style = \"text-align: right;\">0.225</td><td style = \"text-align: right;\">373.757</td><td style = \"text-align: right;\">4553.3</td><td style = \"text-align: right;\">0.769607</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0241511</td><td style = \"text-align: right;\">0.487202</td><td style = \"text-align: right;\">0.403484</td><td style = \"text-align: right;\">1.57436</td><td style = \"text-align: right;\">-0.351507</td><td style = \"text-align: right;\">0.626374</td><td style = \"text-align: right;\">0.679913</td><td style = \"text-align: right;\">5.90539</td><td style = \"text-align: right;\">1.57948</td><td style = \"text-align: right;\">1.61003</td><td style = \"text-align: right;\">1.23545</td><td style = \"text-align: right;\">1.7037</td><td style = \"text-align: right;\">1.7403</td><td style = \"text-align: right;\">2.00819</td><td style = \"text-align: right;\">3.05781</td><td style = \"text-align: right;\">1.05213</td><td style = \"text-align: right;\">0.80077</td><td style = \"text-align: right;\">0.256359</td><td style = \"text-align: right;\">0.295576</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: right;\">518.03</td><td style = \"text-align: right;\">365.844</td><td style = \"text-align: right;\">90.5512</td><td style = \"text-align: right;\">0.0666667</td><td style = \"text-align: right;\">196.242</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">381.979</td><td style = \"text-align: right;\">4501.88</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.351323</td><td style = \"text-align: right;\">0.403484</td><td style = \"text-align: right;\">0.994863</td><td style = \"text-align: right;\">-0.351507</td><td style = \"text-align: right;\">0.444787</td><td style = \"text-align: right;\">0.626747</td><td style = \"text-align: right;\">5.87608</td><td style = \"text-align: right;\">1.62676</td><td style = \"text-align: right;\">1.30132</td><td style = \"text-align: right;\">1.30742</td><td style = \"text-align: right;\">1.59823</td><td style = \"text-align: right;\">1.8381</td><td style = \"text-align: right;\">2.02379</td><td style = \"text-align: right;\">2.87786</td><td style = \"text-align: right;\">1.10058</td><td style = \"text-align: right;\">0.80256</td><td style = \"text-align: right;\">0.255236</td><td style = \"text-align: right;\">0.296529</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: right;\">479.798</td><td style = \"text-align: right;\">342.976</td><td style = \"text-align: right;\">91.6667</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">273.464</td><td style = \"text-align: right;\">0.225</td><td style = \"text-align: right;\">397.793</td><td style = \"text-align: right;\">4501.88</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.427279</td><td style = \"text-align: right;\">0.69506</td><td style = \"text-align: right;\">0.882437</td><td style = \"text-align: right;\">-0.351507</td><td style = \"text-align: right;\">0.456711</td><td style = \"text-align: right;\">0.586445</td><td style = \"text-align: right;\">5.87467</td><td style = \"text-align: right;\">1.67177</td><td style = \"text-align: right;\">1.45526</td><td style = \"text-align: right;\">1.35657</td><td style = \"text-align: right;\">1.60832</td><td style = \"text-align: right;\">2.20228</td><td style = \"text-align: right;\">2.02752</td><td style = \"text-align: right;\">5.91963</td><td style = \"text-align: right;\">1.17407</td><td style = \"text-align: right;\">0.804344</td><td style = \"text-align: right;\">0.254117</td><td style = \"text-align: right;\">0.297483</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: right;\">458.806</td><td style = \"text-align: right;\">332.677</td><td style = \"text-align: right;\">90.5109</td><td style = \"text-align: right;\">0.0916667</td><td style = \"text-align: right;\">196.37</td><td style = \"text-align: right;\">0.183333</td><td style = \"text-align: right;\">564.007</td><td style = \"text-align: right;\">4501.88</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.655353</td><td style = \"text-align: right;\">0.750359</td><td style = \"text-align: right;\">0.882437</td><td style = \"text-align: right;\">-0.0791252</td><td style = \"text-align: right;\">0.247858</td><td style = \"text-align: right;\">0.7382</td><td style = \"text-align: right;\">5.81818</td><td style = \"text-align: right;\">1.65621</td><td style = \"text-align: right;\">1.54826</td><td style = \"text-align: right;\">1.1698</td><td style = \"text-align: right;\">1.65546</td><td style = \"text-align: right;\">1.95841</td><td style = \"text-align: right;\">2.01497</td><td style = \"text-align: right;\">3.94875</td><td style = \"text-align: right;\">1.29526</td><td style = \"text-align: right;\">0.80612</td><td style = \"text-align: right;\">0.253004</td><td style = \"text-align: right;\">0.298436</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: right;\">434.523</td><td style = \"text-align: right;\">318.434</td><td style = \"text-align: right;\">90.5797</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">232.228</td><td style = \"text-align: right;\">0.233333</td><td style = \"text-align: right;\">485.525</td><td style = \"text-align: right;\">4501.88</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.660289</td><td style = \"text-align: right;\">0.743504</td><td style = \"text-align: right;\">0.882437</td><td style = \"text-align: right;\">0.231646</td><td style = \"text-align: right;\">0.203656</td><td style = \"text-align: right;\">0.82315</td><td style = \"text-align: right;\">5.71539</td><td style = \"text-align: right;\">1.63474</td><td style = \"text-align: right;\">1.57396</td><td style = \"text-align: right;\">1.31778</td><td style = \"text-align: right;\">1.78394</td><td style = \"text-align: right;\">2.06664</td><td style = \"text-align: right;\">2.01801</td><td style = \"text-align: right;\">3.99746</td><td style = \"text-align: right;\">1.18475</td><td style = \"text-align: right;\">0.807889</td><td style = \"text-align: right;\">0.251896</td><td style = \"text-align: right;\">0.29939</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: right;\">431.583</td><td style = \"text-align: right;\">307.068</td><td style = \"text-align: right;\">90.2778</td><td style = \"text-align: right;\">0.0833333</td><td style = \"text-align: right;\">262.569</td><td style = \"text-align: right;\">0.191667</td><td style = \"text-align: right;\">335.503</td><td style = \"text-align: right;\">4501.88</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.472143</td><td style = \"text-align: right;\">0.403027</td><td style = \"text-align: right;\">0.882437</td><td style = \"text-align: right;\">-0.0151429</td><td style = \"text-align: right;\">0.287664</td><td style = \"text-align: right;\">0.637455</td><td style = \"text-align: right;\">5.75785</td><td style = \"text-align: right;\">1.64348</td><td style = \"text-align: right;\">1.43099</td><td style = \"text-align: right;\">1.29129</td><td style = \"text-align: right;\">1.87233</td><td style = \"text-align: right;\">1.90119</td><td style = \"text-align: right;\">2.02247</td><td style = \"text-align: right;\">5.22125</td><td style = \"text-align: right;\">1.24478</td><td style = \"text-align: right;\">0.80965</td><td style = \"text-align: right;\">0.250792</td><td style = \"text-align: right;\">0.300343</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">11</td><td style = \"text-align: right;\">409.154</td><td style = \"text-align: right;\">304.464</td><td style = \"text-align: right;\">89.3333</td><td style = \"text-align: right;\">0.0916667</td><td style = \"text-align: right;\">286.384</td><td style = \"text-align: right;\">0.183333</td><td style = \"text-align: right;\">404.496</td><td style = \"text-align: right;\">4501.88</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.371912</td><td style = \"text-align: right;\">0.377434</td><td style = \"text-align: right;\">0.825767</td><td style = \"text-align: right;\">-0.0151429</td><td style = \"text-align: right;\">0.228722</td><td style = \"text-align: right;\">0.737257</td><td style = \"text-align: right;\">5.71666</td><td style = \"text-align: right;\">1.61573</td><td style = \"text-align: right;\">1.32592</td><td style = \"text-align: right;\">1.54768</td><td style = \"text-align: right;\">1.87203</td><td style = \"text-align: right;\">1.87283</td><td style = \"text-align: right;\">1.99923</td><td style = \"text-align: right;\">3.44148</td><td style = \"text-align: right;\">1.15661</td><td style = \"text-align: right;\">0.811405</td><td style = \"text-align: right;\">0.249693</td><td style = \"text-align: right;\">0.301297</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">12</td><td style = \"text-align: right;\">431.466</td><td style = \"text-align: right;\">320.432</td><td style = \"text-align: right;\">88.6667</td><td style = \"text-align: right;\">0.075</td><td style = \"text-align: right;\">325.956</td><td style = \"text-align: right;\">0.225</td><td style = \"text-align: right;\">442.405</td><td style = \"text-align: right;\">4501.88</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.320993</td><td style = \"text-align: right;\">0.340416</td><td style = \"text-align: right;\">0.628336</td><td style = \"text-align: right;\">-0.0151429</td><td style = \"text-align: right;\">0.172822</td><td style = \"text-align: right;\">0.897383</td><td style = \"text-align: right;\">5.71301</td><td style = \"text-align: right;\">1.54722</td><td style = \"text-align: right;\">1.43499</td><td style = \"text-align: right;\">1.51414</td><td style = \"text-align: right;\">1.79225</td><td style = \"text-align: right;\">1.90931</td><td style = \"text-align: right;\">1.97938</td><td style = \"text-align: right;\">3.63769</td><td style = \"text-align: right;\">1.15661</td><td style = \"text-align: right;\">0.813152</td><td style = \"text-align: right;\">0.248599</td><td style = \"text-align: right;\">0.30225</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">13</td><td style = \"text-align: right;\">437.577</td><td style = \"text-align: right;\">317.281</td><td style = \"text-align: right;\">87.6712</td><td style = \"text-align: right;\">0.075</td><td style = \"text-align: right;\">242.616</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">448.844</td><td style = \"text-align: right;\">4501.88</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.765625</td><td style = \"text-align: right;\">0.0</td><td style = \"text-align: right;\">0.173346</td><td style = \"text-align: right;\">0.211994</td><td style = \"text-align: right;\">0.628336</td><td style = \"text-align: right;\">-0.590984</td><td style = \"text-align: right;\">0.314364</td><td style = \"text-align: right;\">0.892425</td><td style = \"text-align: right;\">5.72093</td><td style = \"text-align: right;\">1.60995</td><td style = \"text-align: right;\">1.49051</td><td style = \"text-align: right;\">1.41944</td><td style = \"text-align: right;\">1.66548</td><td style = \"text-align: right;\">1.84603</td><td style = \"text-align: right;\">1.98897</td><td style = \"text-align: right;\">3.79347</td><td style = \"text-align: right;\">1.03415</td><td style = \"text-align: right;\">0.814892</td><td style = \"text-align: right;\">0.24751</td><td style = \"text-align: right;\">0.303204</td></tr><tr><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td><td style = \"text-align: right;\">&vellip;</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54641</td><td style = \"text-align: right;\">121.863</td><td style = \"text-align: right;\">110.971</td><td style = \"text-align: right;\">43.4109</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">213.091</td><td style = \"text-align: right;\">0.233333</td><td style = \"text-align: right;\">180.069</td><td style = \"text-align: right;\">6656.57</td><td style = \"text-align: right;\">0.929097</td><td style = \"text-align: right;\">0.921875</td><td style = \"text-align: right;\">1.04688</td><td style = \"text-align: right;\">0.75</td><td style = \"text-align: right;\">0.0593139</td><td style = \"text-align: right;\">-0.593012</td><td style = \"text-align: right;\">-0.657579</td><td style = \"text-align: right;\">-0.364122</td><td style = \"text-align: right;\">-0.756294</td><td style = \"text-align: right;\">0.125052</td><td style = \"text-align: right;\">0.939643</td><td style = \"text-align: right;\">3.72856</td><td style = \"text-align: right;\">0.956627</td><td style = \"text-align: right;\">0.381284</td><td style = \"text-align: right;\">1.05477</td><td style = \"text-align: right;\">1.04898</td><td style = \"text-align: right;\">1.64853</td><td style = \"text-align: right;\">1.8625</td><td style = \"text-align: right;\">2.58956</td><td style = \"text-align: right;\">1.03266</td><td style = \"text-align: right;\">0.0800082</td><td style = \"text-align: right;\">0.0112458</td><td style = \"text-align: right;\">0.974505</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54642</td><td style = \"text-align: right;\">119.335</td><td style = \"text-align: right;\">139.611</td><td style = \"text-align: right;\">44.7761</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">128.359</td><td style = \"text-align: right;\">0.225</td><td style = \"text-align: right;\">107.71</td><td style = \"text-align: right;\">6964.2</td><td style = \"text-align: right;\">0.949536</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">1.04688</td><td style = \"text-align: right;\">0.75</td><td style = \"text-align: right;\">0.071959</td><td style = \"text-align: right;\">-0.614367</td><td style = \"text-align: right;\">-0.657579</td><td style = \"text-align: right;\">-0.428589</td><td style = \"text-align: right;\">-0.756294</td><td style = \"text-align: right;\">0.104631</td><td style = \"text-align: right;\">0.836616</td><td style = \"text-align: right;\">4.15283</td><td style = \"text-align: right;\">0.849189</td><td style = \"text-align: right;\">0.362244</td><td style = \"text-align: right;\">1.00715</td><td style = \"text-align: right;\">1.0341</td><td style = \"text-align: right;\">1.63988</td><td style = \"text-align: right;\">1.8603</td><td style = \"text-align: right;\">2.19102</td><td style = \"text-align: right;\">0.52732</td><td style = \"text-align: right;\">0.0769253</td><td style = \"text-align: right;\">0.0111949</td><td style = \"text-align: right;\">0.97549</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54643</td><td style = \"text-align: right;\">130.133</td><td style = \"text-align: right;\">145.051</td><td style = \"text-align: right;\">38.2979</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">57.6779</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">49.5886</td><td style = \"text-align: right;\">6560.32</td><td style = \"text-align: right;\">0.920227</td><td style = \"text-align: right;\">0.90625</td><td style = \"text-align: right;\">1.04688</td><td style = \"text-align: right;\">0.671875</td><td style = \"text-align: right;\">0.0859694</td><td style = \"text-align: right;\">-0.529497</td><td style = \"text-align: right;\">-0.550806</td><td style = \"text-align: right;\">-0.0391027</td><td style = \"text-align: right;\">-0.756294</td><td style = \"text-align: right;\">0.175327</td><td style = \"text-align: right;\">0.675683</td><td style = \"text-align: right;\">4.2475</td><td style = \"text-align: right;\">0.709025</td><td style = \"text-align: right;\">0.363635</td><td style = \"text-align: right;\">0.811772</td><td style = \"text-align: right;\">0.835612</td><td style = \"text-align: right;\">1.43301</td><td style = \"text-align: right;\">1.85987</td><td style = \"text-align: right;\">2.36052</td><td style = \"text-align: right;\">0.354446</td><td style = \"text-align: right;\">0.0738416</td><td style = \"text-align: right;\">0.0111443</td><td style = \"text-align: right;\">0.976474</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54644</td><td style = \"text-align: right;\">133.322</td><td style = \"text-align: right;\">136.515</td><td style = \"text-align: right;\">29.6552</td><td style = \"text-align: right;\">0.0916667</td><td style = \"text-align: right;\">106.538</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">148.642</td><td style = \"text-align: right;\">6296.96</td><td style = \"text-align: right;\">0.901021</td><td style = \"text-align: right;\">0.875</td><td style = \"text-align: right;\">1.04688</td><td style = \"text-align: right;\">0.671875</td><td style = \"text-align: right;\">0.0898703</td><td style = \"text-align: right;\">-0.244847</td><td style = \"text-align: right;\">-0.442019</td><td style = \"text-align: right;\">0.788219</td><td style = \"text-align: right;\">-0.720031</td><td style = \"text-align: right;\">0.432089</td><td style = \"text-align: right;\">0.600267</td><td style = \"text-align: right;\">4.25995</td><td style = \"text-align: right;\">0.590881</td><td style = \"text-align: right;\">0.729092</td><td style = \"text-align: right;\">0.797729</td><td style = \"text-align: right;\">0.7548</td><td style = \"text-align: right;\">1.35215</td><td style = \"text-align: right;\">1.82143</td><td style = \"text-align: right;\">2.3244</td><td style = \"text-align: right;\">0.643716</td><td style = \"text-align: right;\">0.0707573</td><td style = \"text-align: right;\">0.0110939</td><td style = \"text-align: right;\">0.977458</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54645</td><td style = \"text-align: right;\">129.664</td><td style = \"text-align: right;\">121.797</td><td style = \"text-align: right;\">21.4765</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">117.761</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">312.402</td><td style = \"text-align: right;\">6004.38</td><td style = \"text-align: right;\">0.879266</td><td style = \"text-align: right;\">0.84375</td><td style = \"text-align: right;\">1.03125</td><td style = \"text-align: right;\">0.65625</td><td style = \"text-align: right;\">0.0933321</td><td style = \"text-align: right;\">0.0787615</td><td style = \"text-align: right;\">-0.021643</td><td style = \"text-align: right;\">0.788219</td><td style = \"text-align: right;\">-0.646163</td><td style = \"text-align: right;\">0.527211</td><td style = \"text-align: right;\">0.504226</td><td style = \"text-align: right;\">3.71803</td><td style = \"text-align: right;\">0.481425</td><td style = \"text-align: right;\">0.322644</td><td style = \"text-align: right;\">0.630915</td><td style = \"text-align: right;\">0.56991</td><td style = \"text-align: right;\">1.17159</td><td style = \"text-align: right;\">1.83219</td><td style = \"text-align: right;\">2.23336</td><td style = \"text-align: right;\">0.726762</td><td style = \"text-align: right;\">0.0676723</td><td style = \"text-align: right;\">0.0110437</td><td style = \"text-align: right;\">0.978443</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54646</td><td style = \"text-align: right;\">86.1542</td><td style = \"text-align: right;\">77.9021</td><td style = \"text-align: right;\">8.27586</td><td style = \"text-align: right;\">0.075</td><td style = \"text-align: right;\">79.0956</td><td style = \"text-align: right;\">0.166667</td><td style = \"text-align: right;\">475.644</td><td style = \"text-align: right;\">5261.27</td><td style = \"text-align: right;\">0.826335</td><td style = \"text-align: right;\">0.828125</td><td style = \"text-align: right;\">1.03125</td><td style = \"text-align: right;\">0.65625</td><td style = \"text-align: right;\">0.0472496</td><td style = \"text-align: right;\">0.36716</td><td style = \"text-align: right;\">0.601534</td><td style = \"text-align: right;\">0.808365</td><td style = \"text-align: right;\">-0.603186</td><td style = \"text-align: right;\">0.431269</td><td style = \"text-align: right;\">0.830037</td><td style = \"text-align: right;\">3.00566</td><td style = \"text-align: right;\">0.522112</td><td style = \"text-align: right;\">0.591662</td><td style = \"text-align: right;\">1.16232</td><td style = \"text-align: right;\">1.3782</td><td style = \"text-align: right;\">1.1644</td><td style = \"text-align: right;\">1.86566</td><td style = \"text-align: right;\">2.03596</td><td style = \"text-align: right;\">0.693233</td><td style = \"text-align: right;\">0.0645867</td><td style = \"text-align: right;\">0.0109937</td><td style = \"text-align: right;\">0.979427</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54647</td><td style = \"text-align: right;\">68.1205</td><td style = \"text-align: right;\">60.3074</td><td style = \"text-align: right;\">7.74648</td><td style = \"text-align: right;\">0.0583333</td><td style = \"text-align: right;\">238.933</td><td style = \"text-align: right;\">0.166667</td><td style = \"text-align: right;\">369.849</td><td style = \"text-align: right;\">5222.91</td><td style = \"text-align: right;\">0.822793</td><td style = \"text-align: right;\">0.828125</td><td style = \"text-align: right;\">0.90625</td><td style = \"text-align: right;\">0.65625</td><td style = \"text-align: right;\">0.0554886</td><td style = \"text-align: right;\">0.644434</td><td style = \"text-align: right;\">0.690176</td><td style = \"text-align: right;\">0.831197</td><td style = \"text-align: right;\">-0.00418329</td><td style = \"text-align: right;\">0.184616</td><td style = \"text-align: right;\">0.950029</td><td style = \"text-align: right;\">2.6684</td><td style = \"text-align: right;\">0.671326</td><td style = \"text-align: right;\">0.508138</td><td style = \"text-align: right;\">1.33057</td><td style = \"text-align: right;\">1.42179</td><td style = \"text-align: right;\">1.15238</td><td style = \"text-align: right;\">1.92002</td><td style = \"text-align: right;\">1.90658</td><td style = \"text-align: right;\">0.906306</td><td style = \"text-align: right;\">0.0615004</td><td style = \"text-align: right;\">0.010944</td><td style = \"text-align: right;\">0.980411</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54648</td><td style = \"text-align: right;\">75.7105</td><td style = \"text-align: right;\">64.4951</td><td style = \"text-align: right;\">9.92908</td><td style = \"text-align: right;\">0.0666667</td><td style = \"text-align: right;\">267.774</td><td style = \"text-align: right;\">0.158333</td><td style = \"text-align: right;\">451.475</td><td style = \"text-align: right;\">5254.39</td><td style = \"text-align: right;\">0.824835</td><td style = \"text-align: right;\">0.828125</td><td style = \"text-align: right;\">0.90625</td><td style = \"text-align: right;\">0.65625</td><td style = \"text-align: right;\">0.0617459</td><td style = \"text-align: right;\">0.690847</td><td style = \"text-align: right;\">0.708307</td><td style = \"text-align: right;\">0.831197</td><td style = \"text-align: right;\">0.378587</td><td style = \"text-align: right;\">0.103443</td><td style = \"text-align: right;\">0.900107</td><td style = \"text-align: right;\">2.79309</td><td style = \"text-align: right;\">0.661101</td><td style = \"text-align: right;\">0.5677</td><td style = \"text-align: right;\">1.27127</td><td style = \"text-align: right;\">1.31002</td><td style = \"text-align: right;\">1.09583</td><td style = \"text-align: right;\">1.90485</td><td style = \"text-align: right;\">1.92827</td><td style = \"text-align: right;\">1.06334</td><td style = \"text-align: right;\">0.0584135</td><td style = \"text-align: right;\">0.0108945</td><td style = \"text-align: right;\">0.981396</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54649</td><td style = \"text-align: right;\">75.9789</td><td style = \"text-align: right;\">64.6679</td><td style = \"text-align: right;\">11.2676</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">216.597</td><td style = \"text-align: right;\">0.241667</td><td style = \"text-align: right;\">561.411</td><td style = \"text-align: right;\">5250.69</td><td style = \"text-align: right;\">0.824099</td><td style = \"text-align: right;\">0.828125</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">0.65625</td><td style = \"text-align: right;\">0.067418</td><td style = \"text-align: right;\">0.592894</td><td style = \"text-align: right;\">0.616308</td><td style = \"text-align: right;\">0.831197</td><td style = \"text-align: right;\">0.267114</td><td style = \"text-align: right;\">0.189223</td><td style = \"text-align: right;\">0.940027</td><td style = \"text-align: right;\">2.88671</td><td style = \"text-align: right;\">0.724244</td><td style = \"text-align: right;\">0.993482</td><td style = \"text-align: right;\">1.37487</td><td style = \"text-align: right;\">1.47786</td><td style = \"text-align: right;\">1.17611</td><td style = \"text-align: right;\">1.87851</td><td style = \"text-align: right;\">1.98421</td><td style = \"text-align: right;\">1.05736</td><td style = \"text-align: right;\">0.0553261</td><td style = \"text-align: right;\">0.0108453</td><td style = \"text-align: right;\">0.98238</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54650</td><td style = \"text-align: right;\">85.1731</td><td style = \"text-align: right;\">53.4619</td><td style = \"text-align: right;\">12.766</td><td style = \"text-align: right;\">0.1</td><td style = \"text-align: right;\">87.1228</td><td style = \"text-align: right;\">0.191667</td><td style = \"text-align: right;\">723.209</td><td style = \"text-align: right;\">5296.86</td><td style = \"text-align: right;\">0.82818</td><td style = \"text-align: right;\">0.828125</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">0.65625</td><td style = \"text-align: right;\">0.0617491</td><td style = \"text-align: right;\">0.515769</td><td style = \"text-align: right;\">0.400748</td><td style = \"text-align: right;\">0.831197</td><td style = \"text-align: right;\">0.267114</td><td style = \"text-align: right;\">0.213384</td><td style = \"text-align: right;\">0.846622</td><td style = \"text-align: right;\">2.97782</td><td style = \"text-align: right;\">0.869867</td><td style = \"text-align: right;\">0.874985</td><td style = \"text-align: right;\">1.37341</td><td style = \"text-align: right;\">1.59993</td><td style = \"text-align: right;\">1.45806</td><td style = \"text-align: right;\">1.97807</td><td style = \"text-align: right;\">2.47428</td><td style = \"text-align: right;\">1.06334</td><td style = \"text-align: right;\">0.0522382</td><td style = \"text-align: right;\">0.0107962</td><td style = \"text-align: right;\">0.983365</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54651</td><td style = \"text-align: right;\">87.1165</td><td style = \"text-align: right;\">54.5148</td><td style = \"text-align: right;\">12.0567</td><td style = \"text-align: right;\">0.0583333</td><td style = \"text-align: right;\">119.175</td><td style = \"text-align: right;\">0.183333</td><td style = \"text-align: right;\">699.266</td><td style = \"text-align: right;\">5337.48</td><td style = \"text-align: right;\">0.832343</td><td style = \"text-align: right;\">0.828125</td><td style = \"text-align: right;\">0.96875</td><td style = \"text-align: right;\">0.65625</td><td style = \"text-align: right;\">0.0467947</td><td style = \"text-align: right;\">0.428224</td><td style = \"text-align: right;\">0.400748</td><td style = \"text-align: right;\">0.824481</td><td style = \"text-align: right;\">0.267114</td><td style = \"text-align: right;\">0.138168</td><td style = \"text-align: right;\">0.89008</td><td style = \"text-align: right;\">2.94935</td><td style = \"text-align: right;\">0.855206</td><td style = \"text-align: right;\">0.74155</td><td style = \"text-align: right;\">1.06727</td><td style = \"text-align: right;\">1.40847</td><td style = \"text-align: right;\">1.37672</td><td style = \"text-align: right;\">1.95078</td><td style = \"text-align: right;\">2.45472</td><td style = \"text-align: right;\">0.962067</td><td style = \"text-align: right;\">0.0491497</td><td style = \"text-align: right;\">0.0107474</td><td style = \"text-align: right;\">0.984349</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">54652</td><td style = \"text-align: right;\">145.266</td><td style = \"text-align: right;\">94.5023</td><td style = \"text-align: right;\">24.6575</td><td style = \"text-align: right;\">0.0833333</td><td style = \"text-align: right;\">98.8988</td><td style = \"text-align: right;\">0.166667</td><td style = \"text-align: right;\">386.704</td><td style = \"text-align: right;\">5149.3</td><td style = \"text-align: right;\">0.818191</td><td style = \"text-align: right;\">0.8125</td><td style = \"text-align: right;\">1.01562</td><td style = \"text-align: right;\">0.640625</td><td style = \"text-align: right;\">0.0323528</td><td style = \"text-align: right;\">0.553016</td><td style = \"text-align: right;\">0.513564</td><td style = \"text-align: right;\">0.710322</td><td style = \"text-align: right;\">0.430966</td><td style = \"text-align: right;\">0.0869686</td><td style = \"text-align: right;\">0.665562</td><td style = \"text-align: right;\">3.23861</td><td style = \"text-align: right;\">0.677204</td><td style = \"text-align: right;\">0.631007</td><td style = \"text-align: right;\">0.836691</td><td style = \"text-align: right;\">0.730583</td><td style = \"text-align: right;\">1.06796</td><td style = \"text-align: right;\">2.02281</td><td style = \"text-align: right;\">2.69469</td><td style = \"text-align: right;\">1.18189</td><td style = \"text-align: right;\">0.0367915</td><td style = \"text-align: right;\">0.0105543</td><td style = \"text-align: right;\">0.988286</td></tr></tbody></table></div>"
            ],
            "text/latex": [
              "\\begin{tabular}{r|ccccccc}\n",
              "\t& rMSSD & SDNN & pNN50 & LF\\_frequency\\_peak & LF\\_frequency\\_power & HF\\_frequency\\_peak & \\\\\n",
              "\t\\hline\n",
              "\t& Float64 & Float64 & Float64 & Float64 & Float64 & Float64 & \\\\\n",
              "\t\\hline\n",
              "\t1 & 485.018 & 433.173 & 87.9032 & 0.0916667 & 396.591 & 0.241667 & $\\dots$ \\\\\n",
              "\t2 & 422.248 & 314.127 & 85.6061 & 0.1 & 130.599 & 0.233333 & $\\dots$ \\\\\n",
              "\t3 & 395.127 & 297.914 & 86.3636 & 0.0916667 & 177.055 & 0.225 & $\\dots$ \\\\\n",
              "\t4 & 406.78 & 320.998 & 86.0465 & 0.1 & 174.384 & 0.15 & $\\dots$ \\\\\n",
              "\t5 & 512.473 & 380.493 & 88.8889 & 0.1 & 275.937 & 0.225 & $\\dots$ \\\\\n",
              "\t6 & 518.03 & 365.844 & 90.5512 & 0.0666667 & 196.242 & 0.241667 & $\\dots$ \\\\\n",
              "\t7 & 479.798 & 342.976 & 91.6667 & 0.1 & 273.464 & 0.225 & $\\dots$ \\\\\n",
              "\t8 & 458.806 & 332.677 & 90.5109 & 0.0916667 & 196.37 & 0.183333 & $\\dots$ \\\\\n",
              "\t9 & 434.523 & 318.434 & 90.5797 & 0.1 & 232.228 & 0.233333 & $\\dots$ \\\\\n",
              "\t10 & 431.583 & 307.068 & 90.2778 & 0.0833333 & 262.569 & 0.191667 & $\\dots$ \\\\\n",
              "\t11 & 409.154 & 304.464 & 89.3333 & 0.0916667 & 286.384 & 0.183333 & $\\dots$ \\\\\n",
              "\t12 & 431.466 & 320.432 & 88.6667 & 0.075 & 325.956 & 0.225 & $\\dots$ \\\\\n",
              "\t13 & 437.577 & 317.281 & 87.6712 & 0.075 & 242.616 & 0.241667 & $\\dots$ \\\\\n",
              "\t14 & 421.949 & 308.305 & 86.5248 & 0.1 & 242.366 & 0.125 & $\\dots$ \\\\\n",
              "\t15 & 454.654 & 316.856 & 89.2857 & 0.0916667 & 207.255 & 0.241667 & $\\dots$ \\\\\n",
              "\t16 & 502.545 & 359.272 & 88.9706 & 0.1 & 221.38 & 0.241667 & $\\dots$ \\\\\n",
              "\t17 & 511.773 & 377.242 & 90.2256 & 0.1 & 228.541 & 0.225 & $\\dots$ \\\\\n",
              "\t18 & 471.021 & 365.638 & 89.4737 & 0.1 & 248.958 & 0.241667 & $\\dots$ \\\\\n",
              "\t19 & 390.931 & 314.732 & 85.7143 & 0.0833333 & 260.104 & 0.241667 & $\\dots$ \\\\\n",
              "\t20 & 430.509 & 328.789 & 86.5672 & 0.1 & 257.356 & 0.241667 & $\\dots$ \\\\\n",
              "\t21 & 401.838 & 301.189 & 85.2113 & 0.075 & 253.318 & 0.233333 & $\\dots$ \\\\\n",
              "\t22 & 416.333 & 302.259 & 85.6164 & 0.0916667 & 218.013 & 0.241667 & $\\dots$ \\\\\n",
              "\t23 & 413.883 & 294.018 & 87.6712 & 0.0666667 & 150.704 & 0.158333 & $\\dots$ \\\\\n",
              "\t24 & 388.504 & 278.925 & 88.5135 & 0.0833333 & 158.283 & 0.241667 & $\\dots$ \\\\\n",
              "\t25 & 396.041 & 275.71 & 88.2759 & 0.0916667 & 154.516 & 0.233333 & $\\dots$ \\\\\n",
              "\t26 & 405.729 & 283.755 & 87.7698 & 0.0833333 & 168.74 & 0.166667 & $\\dots$ \\\\\n",
              "\t27 & 418.805 & 300.592 & 87.7698 & 0.1 & 185.249 & 0.166667 & $\\dots$ \\\\\n",
              "\t28 & 410.315 & 294.539 & 89.4366 & 0.075 & 277.597 & 0.233333 & $\\dots$ \\\\\n",
              "\t29 & 411.865 & 300.656 & 90.7801 & 0.0916667 & 172.635 & 0.166667 & $\\dots$ \\\\\n",
              "\t30 & 380.313 & 282.307 & 92.0 & 0.1 & 218.285 & 0.241667 & $\\dots$ \\\\\n",
              "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ &  \\\\\n",
              "\\end{tabular}\n"
            ],
            "text/plain": [
              "\u001b[1m54652×31 DataFrame\n",
              "\u001b[1m   Row │\u001b[1m rMSSD    \u001b[1m SDNN     \u001b[1m pNN50    \u001b[1m LF_frequency_peak \u001b[1m LF_frequency_power \u001b[1m  ⋯\n",
              "       │\u001b[90m Float64  \u001b[90m Float64  \u001b[90m Float64  \u001b[90m Float64           \u001b[90m Float64            \u001b[90m  ⋯\n",
              "───────┼────────────────────────────────────────────────────────────────────────\n",
              "     1 │ 485.018   433.173   87.9032           0.0916667            396.591    ⋯\n",
              "     2 │ 422.248   314.127   85.6061           0.1                  130.599\n",
              "     3 │ 395.127   297.914   86.3636           0.0916667            177.055\n",
              "     4 │ 406.78    320.998   86.0465           0.1                  174.384\n",
              "     5 │ 512.473   380.493   88.8889           0.1                  275.937    ⋯\n",
              "     6 │ 518.03    365.844   90.5512           0.0666667            196.242\n",
              "     7 │ 479.798   342.976   91.6667           0.1                  273.464\n",
              "     8 │ 458.806   332.677   90.5109           0.0916667            196.37\n",
              "     9 │ 434.523   318.434   90.5797           0.1                  232.228    ⋯\n",
              "    10 │ 431.583   307.068   90.2778           0.0833333            262.569\n",
              "    11 │ 409.154   304.464   89.3333           0.0916667            286.384\n",
              "   ⋮   │    ⋮         ⋮         ⋮              ⋮                  ⋮            ⋱\n",
              " 54643 │ 130.133   145.051   38.2979           0.1                   57.6779\n",
              " 54644 │ 133.322   136.515   29.6552           0.0916667            106.538    ⋯\n",
              " 54645 │ 129.664   121.797   21.4765           0.1                  117.761\n",
              " 54646 │  86.1542   77.9021   8.27586          0.075                 79.0956\n",
              " 54647 │  68.1205   60.3074   7.74648          0.0583333            238.933\n",
              " 54648 │  75.7105   64.4951   9.92908          0.0666667            267.774    ⋯\n",
              " 54649 │  75.9789   64.6679  11.2676           0.1                  216.597\n",
              " 54650 │  85.1731   53.4619  12.766            0.1                   87.1228\n",
              " 54651 │  87.1165   54.5148  12.0567           0.0583333            119.175\n",
              " 54652 │ 145.266    94.5023  24.6575           0.0833333             98.8988   ⋯\n",
              "\u001b[36m                                               26 columns and 54631 rows omitted"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "if \"sid\" in names(data)\n",
        "    select!(data, Not(\"sid\"))\n",
        "end\n",
        "\n",
        "foreach(col -> replace!(col, missing => 0.0), eachcol(data))\n",
        "\n",
        "valid_stages = [\"W\", \"N\", \"R\"]\n",
        "data = filter(row -> row.Sleep_Stage in valid_stages, data)\n",
        "\n",
        "label_mapping = Dict(\"W\"=> \"Wake\", \"N\"=> \"NREM\", \"R\"=> \"REM\")\n",
        "data.Sleep_Stage = CategoricalArray([label_mapping[String(x)] for x in data.Sleep_Stage])\n",
        "\n",
        "y = data.Sleep_Stage\n",
        "X = select(data, Not(:Sleep_Stage))\n",
        "non_constant_cols = names(X)[std.(eachcol(Matrix(X))) .> 0.0]\n",
        "X = select(X, non_constant_cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8J0riryKT2f9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8J0riryKT2f9",
        "outputId": "56d25803-faa3-4c12-ab96-bbacb4c406e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "import MLJDecisionTreeInterface ✔\n",
            "import NearestNeighborModels ✔\n",
            "import MLJLinearModels ✔\n",
            "import MLJLIBSVMInterface ✔\n",
            "import EvoTrees ✔\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mFor silent loading, specify `verbosity=0`. \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "CV(\n",
              "  nfolds = 3, \n",
              "  shuffle = true, \n",
              "  rng = Random._GLOBAL_RNG())"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "using MLJ, MLJFlux, Flux, StatsBase, DataFrames, CategoricalArrays\n",
        "using DecisionTree, NearestNeighborModels, MLJLinearModels, LIBSVM, EvoTrees\n",
        "\n",
        "@load DecisionTreeClassifier pkg=DecisionTree\n",
        "@load KNNClassifier pkg=NearestNeighborModels\n",
        "@load LogisticClassifier pkg=MLJLinearModels\n",
        "@load SVC pkg=LIBSVM\n",
        "@load EvoTreeClassifier pkg=EvoTrees\n",
        "\n",
        "input_dim = size(X, 2)\n",
        "output_dim = length(levels(y))\n",
        "\n",
        "deep_net = Chain(\n",
        "    Dense(input_dim, 128, relu),\n",
        "    Dense(128, 64, relu),\n",
        "    Dense(64, output_dim),\n",
        "    Flux.softmax\n",
        ")\n",
        "\n",
        "deep_builder = MLJFlux.GenericBuilder(deep_net)\n",
        "cv = CV(nfolds=3, shuffle=true)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "FPJDV_rhautv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FPJDV_rhautv",
        "outputId": "3aae54c7-f3d3-422e-dc50-46cf72bedf96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating: UnsupervisedPipeline(standardizer = Standardizer(features = Symbol[], …), …)\n",
            "Error with model UnsupervisedPipeline(standardizer = Standardizer(features = Symbol[], …), …): ArgumentError(\"\\n The `prediction_type` of your model needs to be one of: `:deterministic`,\\n `:probabilistic`, or `:interval`. Does your model implement one of these operations:\\n `predict`, `predict_mean`, `predict_mode`, `predict_median`, or `predict_joint`? If so, you can try explicitly specifying `operation=...`\\n or `operations=...` (and consider posting an issue to have the model review it's\\n definition of `MLJModelInterface.prediction_type`). Otherwise, performance\\n evaluation is not supported.\\n\\n\")\n"
          ]
        }
      ],
      "source": [
        "model = Standardizer() |> DecisionTreeClassifier(max_depth=3)\n",
        "\n",
        "println(\"\\n Evaluating: \", model)\n",
        "try\n",
        "    mach = machine(model, X, y)\n",
        "    res = evaluate!(mach, resampling=cv,\n",
        "        measures=[accuracy, macro_f1score, micro_f1score, cross_entropy],\n",
        "        verbosity=0)\n",
        "    acc = round(mean(res.measurement[1]), digits=4)\n",
        "    println(\"→ Accuracy: \", acc)\n",
        "\n",
        "    MLJ.fit!(mach)\n",
        "    model_name = string(typeof(model).name.name)\n",
        "    filename = model_name * \".jls\"\n",
        "    MLJ.save(filename, mach)\n",
        "    println(\"Saved model to $filename\")\n",
        "\n",
        "    ŷ = predict_mode(mach, X)\n",
        "    cm = confusion_matrix(y, ŷ)\n",
        "    println(\"Confusion Matrix:\\n\", cm)\n",
        "catch err\n",
        "    println(\"Error with model $(model): \", err)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J9Yc-Fgbazt3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J9Yc-Fgbazt3",
        "outputId": "e9bb9b26-ee53-415c-87ba-d70b06375867"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating: ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mExtremely small standard deviation encountered in standardization.\n",
            "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJModels ~/.julia/packages/MLJModels/nxeCf/src/builtins/Transformers.jl:425\u001b[39m\n",
            "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mExtremely small standard deviation encountered in standardization.\n",
            "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJModels ~/.julia/packages/MLJModels/nxeCf/src/builtins/Transformers.jl:425\u001b[39m\n",
            "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mExtremely small standard deviation encountered in standardization.\n",
            "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJModels ~/.julia/packages/MLJModels/nxeCf/src/builtins/Transformers.jl:425\u001b[39m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "→ Accuracy: 0.6102\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, …).\n",
            "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mExtremely small standard deviation encountered in standardization.\n",
            "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJModels ~/.julia/packages/MLJModels/nxeCf/src/builtins/Transformers.jl:425\u001b[39m\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:knn_classifier, …).\n"
          ]
        }
      ],
      "source": [
        "model = Standardizer() |> KNNClassifier(K=5)\n",
        "\n",
        "println(\"\\n Evaluating: \", model)\n",
        "try\n",
        "    mach = machine(model, X, y)\n",
        "    res = evaluate!(mach, resampling=cv,\n",
        "        measures=[accuracy, macro_f1score, micro_f1score, cross_entropy],\n",
        "        verbosity=0)\n",
        "    acc = round(mean(res.measurement[1]), digits=4)\n",
        "    println(\"→ Accuracy: \", acc)\n",
        "\n",
        "    MLJ.fit!(mach)\n",
        "    model_name = string(typeof(model).name.name)\n",
        "    filename = model_name * \".jls\"\n",
        "    MLJ.save(filename, mach)\n",
        "    println(\"Saved model to $filename\")\n",
        "\n",
        "    ŷ = predict_mode(mach, X)\n",
        "    cm = confusion_matrix(y, ŷ)\n",
        "    println(\"Confusion Matrix:\\n\", cm)\n",
        "catch err\n",
        "    println(\"Error with model $(model): \", err)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "ACakBANYa1YB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ACakBANYa1YB",
        "outputId": "486a062c-4794-43ba-d34e-47bc329706af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating: ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …)\n",
            "→ Accuracy: 0.7109\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …).\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:standardizer, …).\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mTraining machine(:logistic_classifier, …).\n",
            "\u001b[36m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mSolver: LBFGS{Optim.Options{Float64, Nothing}, @NamedTuple{}}\n",
            "\u001b[36m\u001b[1m│ \u001b[22m\u001b[39m  optim_options: Optim.Options{Float64, Nothing}\n",
            "\u001b[36m\u001b[1m└ \u001b[22m\u001b[39m  lbfgs_options: @NamedTuple{} NamedTuple()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved model to ProbabilisticPipeline.jls\n",
            "Confusion Matrix:\n",
            "ConfusionMatrix{3}([30397 470 2481; 5399 805 672; 6551 201 7676])\n"
          ]
        }
      ],
      "source": [
        "model = Standardizer() |> LogisticClassifier()\n",
        "\n",
        "println(\"\\n Evaluating: \", model)\n",
        "try\n",
        "    mach = machine(model, X, y)\n",
        "    res = evaluate!(mach, resampling=cv,\n",
        "        measures=[accuracy, macro_f1score, micro_f1score, cross_entropy],\n",
        "        verbosity=0)\n",
        "    acc = round(mean(res.measurement[1]), digits=4)\n",
        "    println(\"Accuracy: \", acc)\n",
        "\n",
        "    MLJ.fit!(mach)\n",
        "    model_name = string(typeof(model).name.name)\n",
        "    filename = model_name * \".jls\"\n",
        "    MLJ.save(filename, mach)\n",
        "    println(\"Saved model to $filename\")\n",
        "\n",
        "    ŷ = predict_mode(mach, X)\n",
        "    cm = confusion_matrix(y, ŷ)\n",
        "    println(\"Confusion Matrix:\\n\", cm)\n",
        "catch err\n",
        "    println(\"Error with model $(model): \", err)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "NyKWXSk7a1w7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyKWXSk7a1w7",
        "outputId": "e1383faf-d7ce-49bf-ec6d-89e409900241"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating: UnsupervisedPipeline(standardizer = Standardizer(features = Symbol[], …), …)\n",
            "Error with model UnsupervisedPipeline(standardizer = Standardizer(features = Symbol[], …), …): ArgumentError(\"\\n The `prediction_type` of your model needs to be one of: `:deterministic`,\\n `:probabilistic`, or `:interval`. Does your model implement one of these operations:\\n `predict`, `predict_mean`, `predict_mode`, `predict_median`, or `predict_joint`? If so, you can try explicitly specifying `operation=...`\\n or `operations=...` (and consider posting an issue to have the model review it's\\n definition of `MLJModelInterface.prediction_type`). Otherwise, performance\\n evaluation is not supported.\\n\\n\")\n"
          ]
        }
      ],
      "source": [
        "model = Standardizer() |> SVC()\n",
        "\n",
        "println(\"\\n Evaluating: \", model)\n",
        "try\n",
        "    mach = machine(model, X, y)\n",
        "    res = evaluate!(mach, resampling=cv,\n",
        "        measures=[accuracy, macro_f1score, micro_f1score, cross_entropy],\n",
        "        verbosity=0)\n",
        "    acc = round(mean(res.measurement[1]), digits=4)\n",
        "    println(\"Accuracy: \", acc)\n",
        "\n",
        "    MLJ.fit!(mach)\n",
        "    model_name = string(typeof(model).name.name)\n",
        "    filename = model_name * \".jls\"\n",
        "    MLJ.save(filename, mach)\n",
        "    println(\"Saved model to $filename\")\n",
        "\n",
        "    ŷ = predict_mode(mach, X)\n",
        "    cm = confusion_matrix(y, ŷ)\n",
        "    println(\"Confusion Matrix:\\n\", cm)\n",
        "catch err\n",
        "    println(\"Error with model $(model): \", err)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "AD9Hragza2Rd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD9Hragza2Rd",
        "outputId": "21d5b55c-2ab5-4b81-f348-b4356e6cbe77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating: ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mExtremely small standard deviation encountered in standardization.\n",
            "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJModels ~/.julia/packages/MLJModels/nxeCf/src/builtins/Transformers.jl:425\u001b[39m\n",
            "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mProblem fitting the machine machine(:evo_tree_classifier, …). \n",
            "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/F1Eh6/src/machines.jl:694\u001b[39m\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRunning type checks... \n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mType checks okay. \n",
            "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mProblem fitting machine(:evo_tree_classifier, …)\n",
            "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/F1Eh6/src/machines.jl:766\u001b[39m\n",
            "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mProblem fitting the machine machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …). \n",
            "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/F1Eh6/src/machines.jl:694\u001b[39m\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRunning type checks... \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error with model ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …): CompositeException(Any"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mType checks okay. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[TaskFailedException(Task (failed) @0x00007df54b994fb0)])\n"
          ]
        }
      ],
      "source": [
        "model = Standardizer() |> EvoTreeClassifier(nrounds=100)\n",
        "\n",
        "println(\"\\n Evaluating: \", model)\n",
        "try\n",
        "    mach = machine(model, X, y)\n",
        "    res = evaluate!(mach, resampling=cv,\n",
        "        measures=[accuracy, macro_f1score, micro_f1score, cross_entropy],\n",
        "        verbosity=0)\n",
        "    acc = round(mean(res.measurement[1]), digits=4)\n",
        "    println(\"Accuracy: \", acc)\n",
        "\n",
        "    MLJ.fit!(mach)\n",
        "    model_name = string(typeof(model).name.name)\n",
        "    filename = model_name * \".jls\"\n",
        "    MLJ.save(filename, mach)\n",
        "    println(\"Saved model to $filename\")\n",
        "\n",
        "    ŷ = predict_mode(mach, X)\n",
        "    cm = confusion_matrix(y, ŷ)\n",
        "    println(\"Confusion Matrix:\\n\", cm)\n",
        "catch err\n",
        "    println(\"Error with model $(model): \", err)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "-QT6YdLra2he",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QT6YdLra2he",
        "outputId": "38066835-b96a-4f3d-c317-5cc7bf5c4ae6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Evaluating: ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[33m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[33m\u001b[1mWarning: \u001b[22m\u001b[39mExtremely small standard deviation encountered in standardization.\n",
            "\u001b[33m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJModels ~/.julia/packages/MLJModels/nxeCf/src/builtins/Transformers.jl:425\u001b[39m\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error with model ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …): CompositeException(Any[TaskFailedException(Task (failed) @0x00007df585cd0fb0)])\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mBuilder does not appear to build an architecture compatible with supplied data. \n",
            "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJFlux ~/.julia/packages/MLJFlux/5eWpt/src/fit_utils.jl:14\u001b[39m\n",
            "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mProblem fitting the machine machine(:neural_network_classifier, …). \n",
            "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/F1Eh6/src/machines.jl:694\u001b[39m\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRunning type checks... \n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mType checks okay. \n",
            "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mProblem fitting machine(:neural_network_classifier, …)\n",
            "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/F1Eh6/src/machines.jl:766\u001b[39m\n",
            "\u001b[91m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[91m\u001b[1mError: \u001b[22m\u001b[39mProblem fitting the machine machine(ProbabilisticPipeline(standardizer = Standardizer(features = Symbol[], …), …), …). \n",
            "\u001b[91m\u001b[1m└ \u001b[22m\u001b[39m\u001b[90m@ MLJBase ~/.julia/packages/MLJBase/F1Eh6/src/machines.jl:694\u001b[39m\n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mRunning type checks... \n",
            "\u001b[36m\u001b[1m[ \u001b[22m\u001b[39m\u001b[36m\u001b[1mInfo: \u001b[22m\u001b[39mType checks okay. \n"
          ]
        }
      ],
      "source": [
        "model = Standardizer() |> NeuralNetworkClassifier(\n",
        "    builder=deep_builder,\n",
        "    loss=Flux.Losses.crossentropy,\n",
        "    optimiser=Flux.ADAM(),\n",
        "    epochs=20\n",
        ")\n",
        "println(\"\\n Evaluating: \", model)\n",
        "try\n",
        "    mach = machine(model, X, y)\n",
        "    res = evaluate!(mach, resampling=cv,\n",
        "        measures=[accuracy, macro_f1score, micro_f1score, cross_entropy],\n",
        "        verbosity=0)\n",
        "    acc = round(mean(res.measurement[1]), digits=4)\n",
        "    println(\"Accuracy: \", acc)\n",
        "\n",
        "    MLJ.fit!(mach)\n",
        "    model_name = string(typeof(model).name.name)\n",
        "    filename = model_name * \".jls\"\n",
        "    MLJ.save(filename, mach)\n",
        "    println(\"Saved model to $filename\")\n",
        "\n",
        "    ŷ = predict_mode(mach, X)\n",
        "    cm = confusion_matrix(y, ŷ)\n",
        "    println(\"Confusion Matrix:\\n\", cm)\n",
        "catch err\n",
        "    println(\"Error with model $(model): \", err)\n",
        "end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "m6vd3njpq-bB",
      "metadata": {
        "id": "m6vd3njpq-bB"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Julia",
      "name": "julia"
    },
    "language_info": {
      "name": "julia"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
